<?xml version='1.0' encoding="UTF-8"?>
<!-- $Header: /var/cvsroot/gentoo/xml/htdocs/doc/es/multipath.xml,v 1.5 2011/02/09 19:30:00 chiguire Exp $ -->
<!DOCTYPE guide SYSTEM "/dtd/guide.dtd">

<guide>
<title>Multitrayectos para Gentoo</title>

<author title="Autor">
  <mail link="tsunam"/>
</author>
<author title="Autor">
  <mail link="matthew.summers@liquidustech.com">Matthew Summers</mail>
</author>
<author title="Autor">
  <mail link="richard.anderson@liquidustech.com">Richard Anderson</mail>
</author>
<author title="Autor">
  <mail link="steve.rucker@liquidustech.com">Steve Rucker</mail>
</author>
<author title="Editor">
  <mail link="nightmorph"/>
</author>
<author title="Traductor">
  <mail link="chiguire"/>
</author>

<abstract>
Este documento enseña a configurar servicios de multitrayecto para el
almacenamiento de datos.
</abstract>

<!-- The content of this document is licensed under the CC-BY-SA license -->
<!-- See http://creativecommons.org/licenses/by-sa/2.5 -->
<license/>

<version>3</version>
<date>2011-02-07</date>

<chapter>
<title>Introducción</title>
<section>
<body>

<p>
Los servicios de multitrayecto se despliegan generalmente en entornos
empresariales para proporcionar los medios para almacenamiento de alto
desempeño, con balanceo de carga y tolerante a fallas, localmente o
via red de área de almacenamiento (en inglés SAN). El multitrayecto
facilita que un único dispositivo de almacenamiento tenga acceso
transparente a través de uno o más trayectos. Por ejemplo, si
disponemosde dos conexiones desde un adaptador bus anfitrión (en
inglés HBA) a dos switches de canal de fibra y de ahí a un SAN, al
cargar el módulo y escanear el bus, leerá cuatro trayectos al SAN: los
trayectos del HBA del servidor desde y hacia cada switch de canal de
fibra en el dispositivo de almacenamiento. Para sacarle ventaja a esta
situación, el multitrayecto permite usar cada trayecto de manera
simultánea o independientemente para asegurar una conexión constante y
fiable a los datos almacenados. El multitrayecto proporciona una
sustitución en caso de fallo para todas las conexiones en caso de la
pérdida de un trayecto, permitiendo la disponibilidad constante a
datos críticos, dada la redundancia en el diseño e implementación.
</p>

<p>
En el sentido más básico, el multitrayecto está compuesto de dos
partes: <c>device-mapper</c> y <c>multipath-tools</c>. El mapeador de
dispositivos (en inglés device mapper) es el primer elemento clave de
esta aplicación. Los administradores de sistemas probablemente
conocerán el mapeador de dispositivos por LVM, EVMS, dm-crypt, o en
este caso, multitrayectos. En pocas palabras, trabajar con el mapeador
de dispositivos en el espacio del núcleo toma un dispositivo de bloque
como <path>/dev/sda</path> (todos los objetivos basados en SAN serán
algún tipo de dispositivo SCSI) y lo mapea a otro dispositivo.
</p>

<p>
En un nivel más bajo, el mapeador de dispositivos crea un dispositivo
de bloque virtual que acepta todos los comandos que aceptaría un
dispositivio de bloque normal, pero pasa los datos al dispositivo de
bloque verdadero. Como hemos dicho anteriormente, el proceso de mapeo
se maneja en el espacio del núcleo, no del usuario.
</p>

<p>
Las <b>herramientas multitrayecto</b> son un conjunto de herramientas
que operan en el espacio de usuarios que interactúa con las
herramientas de mapeo de dispositivos, creando estructuras para el
manejo de dispositivos e implementando E/S multitrayecto a nivel del
sistema operativo. En un entorno SAN típico, dispondremos de múltiples
trayectos para el mismo dispositivo de almacenamiento: una tarjeta de
canal de fibra (o dos) en el servidor, que se conecta a un switch que
a su vez conecta al propio dispositivo (tal como explicamos en el
escenario referido anteriormente). Así, los administradores de sistema
posiblemente podrían ver el mismo dispositivo hasta cuatro veces en
esta situación (cada tarjeta vería el LUN dos veces, una vez por cada
trayecto disponible). De manera que, un único disco duro podría ser
reconocido como <path>sda</path>, <path>sdb</path>, <path>sdc</path> y
<path>sdd</path>. Por ejemplo, si fuéramos a montar
<path>/dev/sda</path> en <path>/san1</path>, estaríamos usando un
único trayecto de una tarjeta de canal de fibra al switch y luego a
puerto en el mismo dispositivo de almacenamiento. Si alguno de estos
puntos fallara, podría perder súbitamente el acceso al dispositivo de
almacenamiento y tener que desmontarlo y montar otro
(<path>sdb</path>).
</p>

<p>
Consecuentemente, este escenario dista mucho de ser ideal ya que se
está usando solo un trayecto de cuatro posibilidades. En este punto es
donde se vislumbra el beneficio de las herramientas multitrayecto y de
mapeo de dispositivos. Como hemos explicado antes, el mapeador de
dispositivos crea dispositivos de bloque virtuales que pasan
información a los verdaderos dispositivos.
</p>
</body>
</section>
</chapter>

<chapter>
<title>Instalación y Configuración</title>
<section>
<title>Instalación y Herramientas</title>
<body>

<p>
Debemos hacer emerge <c>multipath-tools</c> y
<c>sg3_utils</c>. Necesitamos encontrar el <c>wwid</c> del disco. Para
esto usaremos <c>sg_vpd</c> (provisto por el paquete
<c>sg3_utils</c>).
</p>

<pre caption="Instalando multipath-tools y haciendo la configuración inicial">
# <i>emerge multipath-tools sg3_utils</i>
<comment>(Reemplace /dev/DISPOSITIVO con el disco para obtener su wwid)</comment>
# <i>/usr/bin/sg_vpd --page=di /dev/DISPOSITIVO</i>
</pre>

<p>
Donde DISPOSITIVO representa el dispositivo sd, el ID regresará con un
<c>0x6</c>. Reemplace <c>0x</c> con <c>3</c> y obtendrá el ID correcto
para suministrar al argumento <c>wwid</c> multitrayecto en el archivo
<path>/etc/multipath.conf</path>. Más sobre esto en el siguiente
capítulo.
</p>
</body>
</section>

<section>
<title>Configuración de Gentoo para usar multitrayectos</title>
<body>

<p>
Para configurar Gentoo para usar multitrayectos, el núcleo necesita
activar las siguiente opciones:
</p>

<pre caption="Agregando soporte para multitrayectos">
Device Drivers  --->
  SCSI device support  --->
    &lt;*&gt; SCSI target support
    &lt;*&gt; SCSI disk support
    [*] Probe all LUNs on each SCSI device
  [*] Multiple devices driver support (RAID and LVM)  --->
    &lt;*&gt;  Multipath I/O support
    &lt;*&gt;  Device mapper support
    &lt;*&gt;    Multipath target
        <comment>(Seleccione su dispositivo de la lista)</comment>)
    &lt;*&gt;      EMC CX/AX multipath support  
    &lt;*&gt;      LSI/Engenio RDAC multipath support  
    &lt;*&gt;      HP MSA multipath support
</pre>

<note>
El <c>scsi_id</c> se obtiene por objetivo. Los discos IDE tienen dos
puntos a los cuales conectarse. Un administrador de sistema tiene la
abilidad de seleccionar un disco como maestro y otro como esclavo, o
activar la selección automática cambiando los switches dip. El scsi_id
es similar. Cada dispositivo o número lógico de unidad (en inglés
Logical Unit Number, o LUN) tiene un identificador único, con una gama
de 0 a 254. Un dispositivio que tiene un ID 0 será descubierto antes
que un dispositivo que tiene un ID, digamos, de 120, porque lleva a
cabo un LIP (barrido del bus SCSI buscando respuestas de dispositivos)
que comienza en 0 y continúa de manera ascendente.
</note>

<p>
En el menú de configuración del núcleo, active CONFIG_SCSI_MULTI_LUN=y
para asegurar que el subsistema SCSI pueba sondear todos los Números
Lógicos de Unidad o LUNs (Esto es recomendado, ya que el barrido
concluirá luego del ID 0 si tiene un dispositivo cuyo ID es <c>0</c>
ninguno en <c>1</c> y otro con ID <c>2</c>. Dicho simplemente,
obtendrá el dispositivo con ID <c>0</c> pero no el de <c>2</c>.) o
cualquier dispositivo necesario para SCSI, como una tarjeta QLogic
2400, que se encuentra en la sección de controladores SCSI de bajo
nivel.
</p>

<p>
Para poder comprender mejor, considere los siguientes escenarios:
</p>

<p>
Habrán tres discos con ID 0, 1 y 2. Sin activar el sondeo de todos los
LUNs (probe all LUNs), serán visibles los IDs 0, 1 y 2 como sda, sdb y
sdc - todos los dispositivos son visibles. Si borramos el disco ID 1,
todavía serán visibles los IDs 0 y 2. Tal vez crea que tenga sentido
ver a sda y sdb ahora (sdc cambiaría a sdb ya que no hay dispositivo
allí). Sin embargo, al no sondear todos los LUNs, el comportamiento
será el siguiente:
</p>

<p>
Escenario 1: Sin el sondeo de todos los LUNs, el barrido empezará,
comprobándose el ID 0, el cual será asignado a sda, continuándose el
barrido buscando a ID 1. Al no detectarse nada allí, el barrido se
detiene y se considerará completo y que todos los dispositivos han
sido detectados aunque haya un dispositivo en ID 2 o en subsecuentes
IDs. Reinicie el equipo para el siguiente escenario.
</p>

<p>
Escenario 2: Si el sondeo de todos los LUNs está activado, el barrido
comienza y se detecta el ID 0. A este ID se le asigna el sda y el
barrido continua al siguiente dispositivo. Si no se detecta algo en el
ID 1, el barrido continua buscando otros dispositivos. El ID 2 será
localizado y asignado a sdb. Si no se detectan más dispositivos (IDs)
más allá, el barrido se considerará completo.
</p>

<note>
Aunque no parezca factible o hasta innecesario tener dispositivos con
LUNs muy espaciados, para tomar en cuenta todas las opciones, todavía
sigue siendo necesario sondear todos los LUNs. Un administrador de
sistema encontrará muchas razones (empresariales o personales) para
esta configuración, de manera que el segundo escenario sería el óptimo
para asegurar que todos los dispositivos sean reconocidos y que le
sean asignado un ID en el proceso de configuración multitrayecto.
</note>

<p>
Así que, una vez sondeados todos los LUNs, serán reconocidos todos los
dispositivos y se le asignará sus ID multitrayecto.
</p>
</body>
</section>
</chapter>

<chapter>
<title>Resumen de Arquitectura</title>
<section>
<body>

<p>
Como parte de las herramientas multitrayecto hay grupos de prioridad
ocupados por los dispositivos mencionados anteriormente. Después de
configurar <c>multipath-tools</c> e iniciarlos con
<c>/etc/init.d/multipath start</c>, puede listar los grupos con
<c>multipath -l</c>. La salida se parecerá a:
</p>

<pre caption="Salida del comando multipath -l">
EVA_SAN (3600508b4001044ee00013000031e0000)
[size=300 GB][features="1 queue_if_no_path"][hwhandler="0"]
\_ round-robin 0 [active]
\_ 0:0:0:1 sda 8:0  [active]
\_ round-robin 0 [enabled]
\_ 0:0:1:1 sdb 8:16 [active]

EVA_SAN2 (3600508b4001044ee0001300003880000)
[size=300 GB][features="1 queue_if_no_path"][hwhandler="0"]
\_ round-robin 0 [active]
\_ 0:0:0:2 sdc 8:32 [active]
\_ round-robin 0 [enabled]
\_ 0:0:1:2 sdd 8:48 [active]
</pre>

<p>
De manera predeterminada, seleccionará el primer grupo prioritario (el
primer de arriba en secuencia round robin para EVA_SAN2, por ejemplo,
siendo <path>sdc</path>). En este caso, debido a la secuencia round
robin rebotará entre dispositivos. Si uno de los trayectos fuera a
fallar, toda la información continuaría por el otro trayecto. Solo
fallaría si todos los dispositivos en un trayecto fallan, pasando al
segundo grupo prioritario.
</p>
</body>
</section>

<section>
<title>Configuración Típica</title>
<body>

<p>
Una configuración típica multitrayecto se parece a:
</p>

<pre caption="Archivo típico de configuración /etc/multipath.conf">
defaults {
udev_dir                /dev
polling_interval        15
selector                "round-robin 0"
path_grouping_policy    group_by_prio
failback                5
path_checker            tur
prio_callout            "/sbin/mpath_prio_tpc /dev/%n"
rr_min_io               100
rr_weight               uniform
no_path_retry           queue
user_friendly_names     yes
}
blacklist {
devnode cciss
devnode fd
devnode hd
devnode md
devnode sr
devnode scd
devnode st
devnode ram
devnode raw
devnode loop
devnode sda
}

multipaths {
multipath {
wwid
<comment>(Para encontrar el wwid, por favor use /usr/bin/sg_vpd --page=di /dev/DISPOSITIVO.
La dirección será en forma de 0x6. Reemplace el 0x con un 3.)</comment>
alias DB_SAN
}
devices {
device {
<comment>(El espacio en blanco es importante en los siguientes dos casos para igualar las especificaciones del proveedor.)</comment>
"IBM     "
"1815      FAStT "
}
}
}
</pre>

<impo>
En sus dispositivos es preferible hacer <c>cat</c>
<path>/sys/block/sd(device)/device/model</path> y <c>cat</c>
<path>/sys/block/device/sd(device)/device/vendor</path>, colocando a
ambos directamente en la sección de dispositivos en el archivo
<path>/etc/multipath.conf</path>. Tal vez no vea siempre los espacios
en blanco que, en este caso, son parte del nombre. Una razón para la
sección de dispositivos es que no todos los nombres de proveedor están
según la costumbre de nombres del núcleo, por lo que esta cadena de
caracteres no siempre se detecta de manera requerida.
</impo>

<p>
Una configuración típica de multitrayectos usando un EVA_SAN donde la
información del dispositivo está en el núcleo en lo que respecta
detección de hardware de SAN, se vería así:
</p>

<pre caption="Configuración EVA_SAN">
multipaths {
multipath {
wwid  3600508b4001044ee00013000031e0000
alias EVA_SAN
}
multipath {
wwid    3600508b4001044ee0001300003880000
alias   EVA_SAN2
}
}
</pre>
</body>
</section>
</chapter>

<chapter>
<title>Estableciendo una Configuración Propia</title>
<section>
<body>

<p>
Realizar una configuración multitrayecto es bastante sencillo, ya que
el único archivo que requiere cambios es
<path>/etc/multipath.conf</path>.
</p>

<p>
Para empezar, ajuste el <b>intervalo de sondeo</b> (en segundos) para
establecer la frecuencia de verificación de la salud del trayecto.
</p>

<p>
Ajustaremos el <b>selector</b> a <c>"round-robin 0"</c>.
</p>

<note>
Este valor round-robin value es el único valor que usaremos para el
selector en esta configuración.
</note>

<p>
El <b>prio_callout</b> puede ser bastante importante, por lo que hay
un número de distintas prioridades para diferentes dispositivos, tales
como:
</p>

<ul>
  <li>mpath_prio_alua</li>
  <li>mpath_prio_emc</li>
  <li>mpath_prio_hds_modular</li>
  <li>mpath_prio_netapp</li>
  <li>mpath_prio_tpc</li>
</ul>

<note>
Para la mayoría de las personas, <c>mpath_prio_tpc</c> será
suficiente, ya que la comprobación es conservadora. Otros dispositivos
como <c>mpath_prio_netapp</c> tienen una funcionalidad especial para
grupos prioritarios, como las aplicaciones en red.
</note>

<p>
La <b>path_grouping_policy</b> tiene unas cuantas opciones diferentes:
failover, multibus, group_by_prio. La opción <c>failover</c> tendrá
solo un disco por grupo prioritario.  La opción <c>multibus</c>
colocará todos los dispositivos en un solo grupo prioritario.  La
opción <c>group_by_prio</c> se le coloca un "valor de prioridad", de
manera de agrupar los trayectos que tengan la misma prioridad,
determinándose los valores de prioridad por llamada (en inglés
callout).
</p>

<p>
A la opción <b>no_path_retry</b> se le coloca <c>queue</c> ya que la
mayoría no quisieran que falle la transmisión de datos. Así que, si
fallan todos los trayectos, los datos se colocarán en cola hasta que
el dispositivo esté disponible de nuevo y en este momento enviará todo
otra vez. Dependiendo de la transferencia, esto podría causar
problemas de carga.
</p>

<p>
El parámetro <b>rr_min_io</b> es la cantidad de operaciones de E/S que
intentadas por trayecto antes de cambiar a otro trayecto en el mismo
grupo. Si <path>sda</path> y <path>sdb</path> estuviesen en el mismo
grupo, rr_min_io haría 100 operaciones de E/S con <path>sda</path>
luego 100 más con <path>sdb</path>, repitiendo así hasta el
final. Este es un parámetro para afinar para cada caso, ya que la
carga de datos y los tamaños de las transferencias/peticiones varían
por empresa. El valor predeterminado del caso es <c>1000</c>, aunque
algunos pueden preferir valores menores para cambiar puertos de switch
con más frecuencia, de ser posible.
</p>

<p>
Los <b>user_friendly_names</b> hacen más fácil determinar con cuál
dispositivo se está trabajando. Por ejemplo, si configura
user_friendly_names a <c>no</c>, entonces verá los WWID en vez de
EVA_SAN para los dispositivos.
</p>
</body>
</section>
</chapter>
</guide>
