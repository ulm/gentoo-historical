<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE guide SYSTEM "/dtd/guide.dtd">

<!-- $Header: /var/cvsroot/gentoo/xml/htdocs/doc/fr/hpc-howto.xml,v 1.5 2007/01/27 20:55:08 cam Exp $ -->

<guide link="/doc/fr/hpc-howto.xml" lang="fr">

<title>Gentoo Linux pour le calcul de haute performance</title>

<author title="Auteur">
  <mail link="marc@adelielinux.com">Marc St-Pierre</mail>
</author>
<author title="Auteur">
  <mail link="benoit@adelielinux.com">Benoit Morin</mail>
</author>
<author title="Assistant/Recherche">
  <mail link="jean-francois@adelielinux.com">Jean-Francois Richard</mail>
</author>
<author title="Assistant/Recherche">
  <mail link="olivier@adelielinux.com">Olivier Crête</mail>
</author>
<author title="Relecteur">
  <mail link="dberkholz@gentoo.org">Donnie Berkholz</mail>
</author>
<author title="Traducteur">
  <mail link="ribosome@gentoo.org">Olivier Fisette</mail>
</author>

<!-- No licensing information; this document has been written by a third-party
     organisation without additional licensing information.

     In other words, this is copyright adelielinux R&D; Gentoo only has
     permission to distribute this document as-is and update it when appropriate
     as long as the adelie linux R&D notice stays
-->

<abstract>
Ce document a été écrit par des membres du centre de recherche et de
développement Adelie Linux et se veut un guide étape par étape permettant de
transformer un système Gentoo en un système pour le calcul de haute performance.
</abstract>

<version>1.6</version>
<date>2006-12-18</date>

<chapter>
<title>Introduction</title>
<section>
<body>

<p>
Gentoo Linux est une variante de Linux qui peut être optimisée automatiquement
et paramétrée pour répondre à tout usage ou besoin spécifique. Ses possibilités
d'adaptation, ses performances extrêmes et sa grande communauté d'utilisateurs
et de développeurs sont les principales caractéristiques de Gentoo.
</p>

<p>
L'outil Portage peut faire de Gentoo Linux un serveur sécurisé idéal, une
station de développement ou de bureautique professionnelle, une console de
jeux, une solution embarquée ou... un système pour le calcul de haute
performance.
</p>

<p>
Ce document vous apprendra comment transformer un système Gentoo en un système
pour le calcul de haute performance (en anglais «&nbsp;High Performance
Computing&nbsp;», ou HPC). Étape par étape, il vous explique quels paquets
logiciels vous seront utiles, et vous montre comment les installer et les
configurer.
</p>

<p>
Vous pouvez obtenir Gentoo Linux à partir du site Web
<uri>http://www.gentoo.org</uri>. Référez-vous à la <uri
link="/doc/fr/">documentation</uri> (en français) disponible sur ce même site
pour procéder à son installation.
</p>

</body>
</section>
</chapter>

<chapter>
<title>Configurer Gentoo pour l'utiliser avec une grappe de calcul</title>
<section>
<title>Optimisations recommandées</title>
<body>

<note>
Dans cette section, nous ferons fréquemment référence au <uri
link="/doc/fr/handbook/">Manuel Gentoo Linux</uri>.
</note>

<p>
Pendant le processus d'installation, vous devrez paramétrer la variable USE
dans le fichier <path>/etc/make.conf</path>. Nous vous suggérons de désactiver
toutes les valeurs par défaut (voir
<path>/etc/make.profile/make.defaults</path>) en les ajoutant sous forme
négative (-option) dans make.conf. Il y a toutefois quelques options que vous
souhaiterez peut-être conserver, par exemple&nbsp;: x86, 3dnow, gpm, mmx, nptl,
nptlonly, sse, ncurses, pam et tcpd. Consultez la documentation relative à la
variable USE pour plus de détails.
</p>

<pre caption="Options USE">
USE="-oss 3dnow -apm -arts -avi -berkdb -crypt -cups -encode -gdbm -gif gpm -gtk
-imlib -java -jpeg -kde -gnome -libg++ -libwww -mikmod mmx -motif -mpeg ncurses
-nls nptl nptlonly -oggvorbis -opengl pam -pdflib -png -python -qt3 -qt4 -qtmt
-quicktime -readline -sdl -slang -spell -ssl -svga tcpd -truetype -X -xml2 -xv
-zlib"
</pre>

<p>
Ou, plus simplement&nbsp;:
</p>

<pre caption="Variable USE - version simplifiée">
USE="-* 3dnow gpm mmx ncurses pam sse tcpd"
</pre>

<note>
L'option USE <e>tcpd</e> augmente la sécurité pour certains paquets logiciels
tels que xinetd.
</note>

<p>
En ce qui concerne le noyau, nous suggérons, pour des raisons de stabilité, les
«&nbsp;vanilla-sources&nbsp;», c'est-à-dire les sources officielles disponibles
sur le site <uri>http://www.kernel.org/</uri>. Vous devrez peut-être choisir
des sources différentes si vous avez besoin du support pour une technologie
particulière telle que xfs.
</p>

<pre caption="Installer les « vanilla-sources »">
# <i>emerge -p syslog-ng vanilla-sources</i>
</pre>

<p>
Lorsque viendra le temps d'installer les divers utilitaires complétant votre
système Gentoo, nous vous suggérons d'installer les paquets suivants&nbsp;:
</p>

<pre caption="Installer quelques paquets nécessaires">
# <i>emerge -p nfs-utils portmap tcpdump ssmtp iptables xinetd</i>
</pre>

</body>
</section>
<section>
<title>Interface de communication (réseau TCP/IP)</title>
<body>

<p>
Une grappe de calcul nécessite une interface de communication pour
interconnecter les nœuds esclaves au nœud maître. Il s'agit typiquement d'un
réseau local (LAN) de type «&nbsp;FastEthernet&nbsp;» ou
«&nbsp;GigaEthernet&nbsp;», cette technologie offrant un ratio performance
versus prix intéressant. Les alternatives incluent les produits <uri
link="http://www.myricom.com/">Myrinet</uri>, <uri
link="http://quadrics.com/">QsNet</uri> et d'autres.
</p>

<p>
Une grappe de calcul contient deux types de nœuds&nbsp;: maître et esclave.
Dans la plupart des cas, la grappe contient un seul nœud maître et plusieurs
nœuds esclaves.
</p>

<p>
Le nœud maître est le serveur de la grappe de calcul. Il est responsable de
fournir les instructions aux nœuds esclaves. Ce serveur exécute habituellement
des services tels que dhcpd, nfs, pbs-server et pbs-sched. Le nœud maître
accepte les tâches et permet aux utilisateurs d'ouvrir des sessions
interactives.
</p>

<p>
Chaque nœud esclave reçoit ses instructions (probablement par ssh ou rsh) du
nœud maître. Puisque les nœuds esclaves sont dédiés aux calculs, ils ne
devraient pas exécuter de services superflus.
</p>

<p>
La suite de ce document assume une configuration similaire à celle proposée
dans le fichier <path>/etc/hosts</path> ci-dessous. Ce fichier devrait être
présent sur tous les nœuds et contenir une entrée pour chaque nœud de la grappe
de calcul.
</p>

<pre caption="/etc/hosts">
# Adelie Linux Research &amp; Development Center
# /etc/hosts

127.0.0.1       localhost

192.168.1.100   master.adelie master

192.168.1.1     node01.adelie node01
192.168.1.2     node02.adelie node02
</pre>

<p>
Pour configurer le réseau local (LAN) de votre grappe de calcul, éditez le
fichier <path>/etc/conf.d/net</path> du nœud maître.
</p>

<pre caption="/etc/conf.d/net">
# Global config file for net.* rc-scripts

# This is basically the ifconfig argument without the ifconfig $iface
#

iface_eth0="192.168.1.100 broadcast 192.168.1.255 netmask 255.255.255.0"
# Network Connection to the outside world using dhcp -- configure as required for you network
iface_eth1="dhcp"
</pre>


<p>
Enfin, configurez un démon DHPC sur le nœud maître afin de ne pas avoir à
configurer le réseau sur chacun des nœuds esclaves.
</p>

<pre caption="/etc/dhcp/dhcpd.conf">
# Adelie Linux Research &amp; Development Center
# /etc/dhcp/dhcpd.conf

log-facility local7;
ddns-update-style none;
use-host-decl-names on;

subnet 192.168.1.0 netmask 255.255.255.0 {
        option domain-name "adelie";
        range 192.168.1.10 192.168.1.99;
        option routers 192.168.1.100;

        host node01.adelie {
                # MAC address of network card on node 01
                hardware ethernet 00:07:e9:0f:e2:d4;
                fixed-address 192.168.1.1;
        }
        host node02.adelie {
                # MAC address of network card on node 02
                hardware ethernet 00:07:e9:0f:e2:6b;
                fixed-address 192.168.1.2;
        }
}
</pre>

</body>
</section>
<section>
<title>NFS/NIS</title>
<body>

<p>
Le «&nbsp;Network File System&nbsp;» (NFS) a été conçu pour permettre à un
ordinateur de monter un système de fichiers situé sur une machine distante
comme si ce système de fichiers était sur le disque dur local. Cela permet le
partage rapide et transparent de fichiers à travers un réseau.
</p>

<p>
Il existe d'autres systèmes dont les fonctionnalités sont comparables à celles
de NFS et qui pourraient être utilisés avec une grappe de calcul. Le <uri
link="http://www.openafs.org">système de fichiers Andrew d'IBM</uri>, qui est
maintenant un projet «&nbsp;open source&nbsp;», offre un mécanisme de partage
de fichiers avec sécurité et performances améliorées. Le <uri
link="http://www.coda.cs.cmu.edu/">système de fichiers Coda</uri> est encore en
développement, mais il est conçu pour bien fonctionner avec les clients
déconnectés. Plusieurs fonctionnalités des systèmes de fichiers Andrew et Coda
seront incorporées dans la prochaine version de <uri
link="http://www.nfsv4.org/">NFS (version 4)</uri>. NFS offre présentement
plusieurs avantages&nbsp;: il est mature, standardisé, bien compris et supporté
par une grande variété de plates-formes.
</p>

<pre caption="Les paquets logiciels pour le support de NFS">
# <i>emerge -p nfs-utils portmap</i>
# <i>emerge nfs-utils portmap</i>
</pre>

<p>
Configurez et installez un noyau supportant NFS version 3 sur tous vos
nœuds&nbsp;:
</p>

<pre caption="Configuration du noyau requise pour utiliser NFS">
CONFIG_NFS_FS=y
CONFIG_NFSD=y
CONFIG_SUNRPC=y
CONFIG_LOCKD=y
CONFIG_NFSD_V3=y
CONFIG_LOCKD_V4=y
</pre>

<p>
Sur le nœud maître, éditez le fichier <path>/etc/hosts.allow</path> pour
permettre les connexions à partir des nœuds esclaves. Si votre grappe de calcul
occupe la plage réseau 192.168.1.0/24, votre fichier <path>hosts.allow</path>
ressemblera à ceci&nbsp;:
</p>

<pre caption="hosts.allow">
portmap:192.168.1.0/255.255.255.0
</pre>

<p>
Éditez le fichier <path>/etc/exports</path> du nœud maître pour exporter une
structure de répertoires pour le travail. Le répertoire /home est un bon choix.
</p>

<pre caption="/etc/exports">
/home/  (rw)
</pre>

<p>
Ajoutez nfs au niveau d'exécution par défaut du nœud maître&nbsp;:
</p>

<pre caption="Ajouter nfs au niveau d'exécution par défaut">
# <i>rc-update add nfs default</i>
</pre>

<p>
Pour monter le système de fichiers nfs exporté du maître, vous devez également
configurer le fichier <path>/etc/fstab</path> de vos nœuds esclaves. Ajoutez-y
la ligne suivante&nbsp;:
</p>

<pre caption="/etc/fstab">
master:/home/   /home   nfs     rw,exec,noauto,nouser,async     0 0
</pre>

<p>
Vous devez aussi exécuter la commande suivante pour que les nœuds montent le
système de fichiers nfs automatiquement&nbsp;:
</p>

<pre caption="Ajouter nfsmount au niveau d'exécution par défaut">
# <i>rc-update add nfsmount default</i>
</pre>

</body>
</section>
<section>
<title>RSH/SSH</title>
<body>

<p>
SSH est un protocole pour l'ouverture de sessions sécurisées à distance (et
pour d'autres services sécurisés) sur un réseau non sécurisé. OpenSSH utilise
la cryptographie à clé publique pour fournir une méthode d'authentification
sécurisée. La première chose à faire pour configurer OpenSSH sur votre grappe
de calcul est de générer une clé publique, qui sera partagée avec les
ordinateurs distants, et une clé privée, qui sera conservée sur le système
local.
</p>

<p>
Pour une utilisation transparente de la grappe de calcul, des clés privée et
publique peuvent être utilisées. Le processus se fait en deux étapes&nbsp;:
</p>

<ul>
  <li>Générer les clés publique et privée.</li>
  <li>Copier la clé publique sur les nœuds esclaves.</li>
</ul>

<p>
Pour l'authentification basée sur l'utilisateur, générez et copiez les clés
comme suit&nbsp;:
</p>

<pre caption="Authentification par clés SSH">
# <i>ssh-keygen -t dsa</i>
Generating public/private dsa key pair.
Enter file in which to save the key (/root/.ssh/id_dsa): /root/.ssh/id_dsa
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /root/.ssh/id_dsa.
Your public key has been saved in /root/.ssh/id_dsa.pub.
The key fingerprint is:
f1:45:15:40:fd:3c:2d:f7:9f:ea:55:df:76:2f:a4:1f root@master

<comment>Attention ! Si vous avez déjà un fichier « authorized_keys »,
vous devez ajouter la clé publique à la fin de ce fichier plutôt
qu'utiliser les commandes suivantes.</comment>

# <i>scp /root/.ssh/id_dsa.pub node01:/root/.ssh/authorized_keys</i>
root@master's password:
id_dsa.pub   100%  234     2.0MB/s   00:00

# <i>scp /root/.ssh/id_dsa.pub node02:/root/.ssh/authorized_keys</i>
root@master's password:
id_dsa.pub   100%  234     2.0MB/s   00:00
</pre>

<note>
Les clés des hôtes doivent avoir une phrase de passe vide. RSA est requis pour
l'authentification basée sur l'hôte.
</note>

<p>
Pour l'authentification basée sur l'hôte, vous devrez également éditer le
fichier <path>/etc/ssh/shosts.equiv</path>.
</p>

<pre caption="/etc/ssh/shosts.equiv">
node01.adelie
node02.adelie
master.adelie
</pre>

<p>
Vous devrez aussi apporter quelques modifications au fichier
<path>/etc/ssh/sshd_config</path>&nbsp;:
</p>

<pre caption="Configuration de sshd">
# $OpenBSD: sshd_config,v 1.42 2001/09/20 20:57:51 mouring Exp $
# This sshd was compiled with PATH=/usr/bin:/bin:/usr/sbin:/sbin

# This is the sshd server system-wide configuration file.  See sshd(8)
# for more information.

# HostKeys for protocol version 2
HostKey /etc/ssh/ssh_host_rsa_key
</pre>

<p>
Si vos applications nécessitent la communication par RSH, vous devrez
installer net-misc/netkit-rsh et sys-apps/xinetd.
</p>

<pre caption="Installer les applications requises">
# <i>emerge -p xinetd</i>
# <i>emerge xinetd</i>
# <i>emerge -p netkit-rsh</i>
# <i>emerge netkit-rsh</i>
</pre>

<p>
Ensuite, configurez le démon rsh. Éditez le fichier
<path>/etc/xinet.d/rsh</path>.
</p>

<pre caption="rsh">
# Adelie Linux Research &amp; Development Center
# /etc/xinetd.d/rsh

service shell
{
        socket_type     = stream
        protocol        = tcp
        wait            = no
        user            = root
        group           = tty
        server          = /usr/sbin/in.rshd
        log_type        = FILE /var/log/rsh
        log_on_success  = PID HOST USERID EXIT DURATION
        log_on_failure  = USERID ATTEMPT
        disable         = no
}
</pre>

<p>
Éditez votre fichier <path>/etc/hosts.allow</path> pour permettre les
connexions par RSH&nbsp;:
</p>

<pre caption="hosts.allow">
# Adelie Linux Research &amp; Development Center
# /etc/hosts.allow

in.rshd:192.168.1.0/255.255.255.0
</pre>

<p>
Alternativement, vous pouvez simplement faire confiance au réseau local de
votre grappe de calcul&nbsp;:
</p>

<pre caption="hosts.allow">
# Adelie Linux Research &amp; Development Center
# /etc/hosts.allow

ALL:192.168.1.0/255.255.255.0
</pre>

<p>
Finalement, configurez l'authentification de l'hôte avec le fichier
<path>/etc/hosts.equiv</path>.
</p>

<pre caption="hosts.equiv">
# Adelie Linux Research &amp; Development Center
# /etc/hosts.equiv

master
node01
node02
</pre>

<p>
Il ne reste plus qu'à ajouter xinetd à votre niveau d'exécution par
défaut&nbsp;:
</p>

<pre caption="Ajouter xinetd au niveau d'exécution par défaut">
# <i>rc-update add xinetd default</i>
</pre>

</body>
</section>
<section>
<title>NTP</title>
<body>

<p>
Le «&nbsp;Network Time Protocol&nbsp;» (NTP) est utilisé pour synchroniser
l'horloge d'un ordinateur client ou serveur avec celle d'un autre serveur ou
source de référence, par exemple une radio, un satellite, un modem ou un
système de positionnement global (GPS). Il assure une précision de l'ordre de
la milliseconde dans un réseau local, ou de quelques dizaines de millisecondes
au maximum dans un réseau étendu (WAN). La synchronisation se fait
relativement au temps universel coordonné (UTC). Une configuration NTP typique
emploie de multiples serveurs redondants et des chemins réseaux variés afin
d'obtenir une exactitude et une fiabilité élevées.
</p>

<p>
Choisissez un serveur géographiquement proche de votre système à partir de la
liste «&nbsp;<uri
link="http://www.eecis.udel.edu/~mills/ntp/servers.html">Public NTP Time
Servers</uri>&nbsp;», puis éditez les fichiers <path>/etc/conf.d/ntp</path> et
<path>/etc/ntp.conf</path> sur le nœud maître.
</p>

<pre caption="/etc/conf.d/ntp sur le nœud maître">
# /etc/conf.d/ntpd

# NOTES:
#  - NTPDATE variables below are used if you wish to set your
#    clock when you start the ntp init.d script
#  - make sure that the NTPDATE_CMD will close by itself ...
#    the init.d script will not attempt to kill/stop it
#  - ntpd will be used to maintain synchronization with a time
#    server regardless of what NTPDATE is set to
#  - read each of the comments above each of the variable

# Comment this out if you dont want the init script to warn
# about not having ntpdate setup
NTPDATE_WARN="n"

# Command to run to set the clock initially
# Most people should just uncomment this line ...
# however, if you know what you're doing, and you
# want to use ntpd to set the clock, change this to 'ntpd'
NTPDATE_CMD="ntpdate"

# Options to pass to the above command
# Most people should just uncomment this variable and
# change 'someserver' to a valid hostname which you
# can aquire from the URL's below
NTPDATE_OPTS="-b ntp1.cmc.ec.gc.ca"

##
# A list of available servers is available here:
# http://www.eecis.udel.edu/~mills/ntp/servers.html
# Please follow the rules of engagement and use a
# Stratum 2 server (unless you qualify for Stratum 1)
##

# Options to pass to the ntpd process that will *always* be run
# Most people should not uncomment this line ...
# however, if you know what you're doing, feel free to tweak
#NTPD_OPTS=""

</pre>

<p>
Éditez ensuite <path>/etc/ntp.conf</path> sur le nœud maître pour paramétrer
une source de synchronisation externe.
</p>

<pre caption="ntp.conf sur le nœud maître">
# Adelie Linux Research &amp; Development Center
# /etc/ntp.conf

# Synchronization source #1
server ntp1.cmc.ec.gc.ca
restrict ntp1.cmc.ec.gc.ca
# Synchronization source #2
server ntp2.cmc.ec.gc.ca
restrict ntp2.cmc.ec.gc.ca
stratum 10
driftfile /etc/ntp.drift.server
logfile  /var/log/ntp
broadcast 192.168.1.255
restrict default kod
restrict 127.0.0.1
restrict 192.168.1.0 mask 255.255.255.0
</pre>

<p>
Après cela, configurez la source de synchronisation de tous les nœuds esclaves
pour qu'ils se réfèrent au nœud maître.
</p>

<pre caption="/etc/conf.d/ntp sur les nœuds esclaves">
# /etc/conf.d/ntpd

NTPDATE_WARN="n"
NTPDATE_CMD="ntpdate"
NTPDATE_OPTS="-b master"
</pre>

<pre caption="ntp.conf sur les nœuds esclaves">
# Adelie Linux Research &amp; Development Center
# /etc/ntp.conf

# Synchronization source #1
server master
restrict master
stratum 11
driftfile /etc/ntp.drift.server
logfile  /var/log/ntp
restrict default kod
restrict 127.0.0.1
</pre>

<p>
Enfin, ajoutez ntpd au niveau d'exécution par défaut sur tous les nœuds&nbsp;:
</p>

<pre caption="Ajouter ntpd au niveau d'exécution par défaut">
# <i>rc-update add ntpd default</i>
</pre>

<note>
NTP ne mettra pas à jour l'horloge locale si la différence de temps entre
cette horloge et la source de synchronisation est trop grande.
</note>

</body>
</section>
<section>
<title>Iptables</title>
<body>

<p>
Vous aurez besoin de iptables pour installer un pare-feu sur votre grappe de
calcul.
</p>

<pre caption="Installer iptables">
# <i>emerge -p iptables</i>
# <i>emerge iptables</i>
</pre>

<p>
Configuration du noyau nécessaire&nbsp;:
</p>

<pre caption="Configuration du noyau pour iptables">
CONFIG_NETFILTER=y
CONFIG_IP_NF_CONNTRACK=y
CONFIG_IP_NF_IPTABLES=y
CONFIG_IP_NF_MATCH_STATE=y
CONFIG_IP_NF_FILTER=y
CONFIG_IP_NF_TARGET_REJECT=y
CONFIG_IP_NF_NAT=y
CONFIG_IP_NF_NAT_NEEDED=y
CONFIG_IP_NF_TARGET_MASQUERADE=y
CONFIG_IP_NF_TARGET_LOG=y
</pre>

<p>
Voici maintenant les règles du pare-feu&nbsp;:
</p>

<pre caption="rule-save">
# Adelie Linux Research &amp; Development Center
# /var/lib/iptables/rule-save

*filter
:INPUT ACCEPT [0:0]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]
-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
-A INPUT -p tcp -m tcp --dport 22 -j ACCEPT
-A INPUT -s 192.168.1.0/255.255.255.0 -i eth1 -j ACCEPT
-A INPUT -s 127.0.0.1 -i lo -j ACCEPT
-A INPUT -p icmp -j ACCEPT
-A INPUT -j LOG
-A INPUT -j REJECT --reject-with icmp-port-unreachable
COMMIT
*nat
:PREROUTING ACCEPT [0:0]
:POSTROUTING ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]
-A POSTROUTING -s 192.168.1.0/255.255.255.0 -j MASQUERADE
COMMIT
</pre>

<p>
Finalement, ajoutez iptables au niveau d'exécution par défaut de tous les
nœuds&nbsp;:
</p>

<pre caption="Ajouter iptables au niveau d'exécution par défaut">
# <i>rc-update add iptables default</i>
</pre>

</body>
</section>
</chapter>

<chapter>
<title>Outils HPC</title>
<section>
<title>OpenPBS</title>
<body>

<p>
«&nbsp;Portable Batch System&nbsp;» (PBS) est un système pour la gestion de
files de travaux et de la répartition de la charge. PBS a été initialement
développé pour la NASA. Il fonctionne sur les environnements UNIX multi
plates-formes en réseau, incluant les grappes de calcul hétérogènes formées de
stations de travail, de superordinateurs et de systèmes massivement
parallèles. Le développement de PBS est assuré par Altair Grid Technologies.
</p>

<pre caption="Installer openpbs">
# <i>emerge -p openpbs</i>
</pre>

<note>
L'ebuild pour OpenPBS n'attribue pas les bonnes permissions aux répertoires
utilisés par OpenPBS dans <path>/var</path>.
</note>

<p>
OpenPBS doit être configuré avant que vous ne puissiez l'utiliser. Les
fichiers qui doivent être personnalisés en fonction de votre système
sont&nbsp;:
</p>

<ul>
  <li>/etc/pbs_environment</li>
  <li>/var/spool/PBS/server_name</li>
  <li>/var/spool/PBS/server_priv/nodes</li>
  <li>/var/spool/PBS/mom_priv/config</li>
  <li>/var/spool/PBS/sched_priv/sched_config</li>
</ul>

<p>
Voici un exemple de sched_config&nbsp;:
</p>

<pre caption="/var/spool/PBS/sched_priv/sched_config">
#
# Create queues and set their attributes.
#
#
# Create and define queue upto4nodes
#
create queue upto4nodes
set queue upto4nodes queue_type = Execution
set queue upto4nodes Priority = 100
set queue upto4nodes resources_max.nodect = 4
set queue upto4nodes resources_min.nodect = 1
set queue upto4nodes enabled = True
set queue upto4nodes started = True
#
# Create and define queue default
#
create queue default
set queue default queue_type = Route
set queue default route_destinations = upto4nodes
set queue default enabled = True
set queue default started = True
#
# Set server attributes.
#
set server scheduling = True
set server acl_host_enable = True
set server default_queue = default
set server log_events = 511
set server mail_from = adm
set server query_other_jobs = True
set server resources_default.neednodes = 1
set server resources_default.nodect = 1
set server resources_default.nodes = 1
set server scheduler_iteration = 60
</pre>

<p>
Pour soumettre une tâche à OpenPBS, la commande <c>qsub</c> est utilisée avec
quelques paramètres optionnels. Dans l'exemple ci-dessous, <c>-l</c> spécifie
les ressources requises, <c>-j</c> redirige la sortie et l'erreur standards et
<c>-m</c> envoie un courrier à l'utilisateur au début (b) et à la fin (e) de
la tâche ou si la tâche est annulée (a).
</p>

<pre caption="Soumettre une tâche">
<comment>(Demande à OpenPBS d'exécuter « monscript » sur 2 nœuds de calcul.)</comment>
# <i>qsub -l nodes=2 -j oe -m abe monscript</i>
</pre>

<p>
Habituellement, les tâches sont soumises à OpenPBS sous forme de scripts.
Parfois, vous voudrez exécuter une tâche manuellement. Pour ce faire, ouvrez
un shell OpenPBS interactif avec l'option <c>-I</c>.
</p>

<pre caption="Ouvrir un shell interactif">
# <i>qsub -I</i>
</pre>

<p>
Pour consulter l'état de vos tâches, utilisez la commande <c>qstat</c>.
</p>

<pre caption="Vérifier l'état des tâches">
# <i>qstat</i>
Job id  Name  User   Time Use S Queue
------  ----  ----   -------- - -----
2.geist STDIN adelie 0        R upto1nodes
</pre>

</body>
</section>
<section>
<title>MPICH</title>
<body>

<p>
Les procédures d'échange de messages (en anglais «&nbsp;message
passing&nbsp;») sont fréquemment utilisées avec certains types de machines
fonctionnant en parallèle, particulièrement celles qui utilisent de la mémoire
distribuée. MPICH est une implémentation gratuite et portable de MPI, le
standard pour les bibliothèques d'échange de messages.
</p>

<p>
L'ebuild pour MPICH fourni par Adelie Linux propose deux options USE&nbsp;:
<e>doc</e> et <e>crypt</e>. Activer <e>doc</e> installera la documentation,
alors qu'activer <e>crypt</e> configurera MPICH pour qu'il utilise <c>ssh</c>
plutôt que <c>rsh</c>.
</p>

<pre caption="Installer MPICH">
# <i>emerge -p mpich</i>
# <i>emerge mpich</i>
</pre>

<p>
Vous devrez peut-être exporter un répertoire de travail sur tous vos nœuds
esclaves dans le fichier <path>/etc/exports</path>&nbsp;:
</p>

<pre caption="/etc/exports">
/home   *(rw)
</pre>

<p>
La plupart des processeurs massivement parallèles (en anglais «&nbsp;massively
parallel processors&nbsp;», MPP) permettent de lancer un programme sur un
nombre spécifique de processeurs&nbsp;; <c>mpirun</c> utilise la commande
appropriée lorsque c'est possible. À l'inverse, les grappes de stations de
travail nécessitent que chaque processus dans une tâche parallèle soit démarré
individuellement (bien qu'il existe des programmes pour aider au démarrage de
ces processus). Puisque les grappes de stations de travail ne sont pas
organisées en MPP à la base, il faut procéder à leur configuration. MPICH
devrait disposer de la liste des stations de travail participantes dans le
fichier <path>machines.LINUX</path> situé dans le répertoire
<path>/usr/share/mpich/</path>. Ce fichier est utilisé par <c>mpirun</c> pour
la sélection des processeurs à utiliser.
</p>

<p>
Éditez ce fichier pour qu'il reflète la configuration de votre grappe et de
votre réseau&nbsp;:
</p>

<pre caption="/usr/share/mpich/machines.LINUX">
# Change this file to contain the machines that you want to use
# to run MPI jobs on.  The format is one host name per line, with either
#    hostname
# or
#    hostname:n
# where n is the number of processors in an SMP.  The hostname should
# be the same as the result from the command "hostname"
master
node01
node02
# node03
# node04
# ...
</pre>

<p>
Utilisez le script <c>tstmachines</c> situé dans <path>/usr/sbin/</path> pour
vous assurer que vous pouvez employer toutes les machines que vous avez listées.
Ce script utilise <c>rsh</c> pour se connecter et liste le contenu d'un
répertoire&nbsp;; ce test vérifie que vous pouvez accéder au nœud distant et
qu'un programme situé dans le répertoire courant sera également visible par le
nœud courant. Si des problèmes surviennent, ils seront affichés&nbsp;; vous
devrez les corriger avant de poursuivre.
</p>

<p>
La seule option à fournir à <c>tstmachines</c> est le nom de l'architecture.
Ce nom correspond à l'extension du fichier contenant la liste des machines.
Par exemple, la commande suivante vérifie qu'un programme dans le répertoire
courant peut être exécuté par toutes les machines dans la liste LINUX.
</p>

<pre caption="Exécuter un test">
# <i>/usr/local/mpich/sbin/tstmachines LINUX</i>
</pre>

<note>
Ce programme ne génère aucune sortie si tout va bien&nbsp;; si vous voulez
savoir ce que le programme fait, utilisez l'option -v (volubile)&nbsp;:
</note>

<pre caption="Exécuter un test en mode volubile">
# <i>/usr/local/mpich/sbin/tstmachines -v LINUX</i>
</pre>

<p>
La sortie de cette commande ressemblera à ce qui suit&nbsp;:
</p>

<pre caption="Sortie de la commande précédente">
Trying true on host1.uoffoo.edu ...
Trying true on host2.uoffoo.edu ...
Trying ls on host1.uoffoo.edu ...
Trying ls on host2.uoffoo.edu ...
Trying user program on host1.uoffoo.edu ...
Trying user program on host2.uoffoo.edu ...
</pre>

<p>
Si <c>tstmachines</c> découvre un problème, il donnera une liste de causes
possibles accompagnée de suggestions pour le régler. En résumé, trois tests
sont effectués&nbsp;:
</p>

<ul>
  <li>
    <e>Est-il possible d'exécuter des processus sur les machines
    distantes&nbsp;?</e> tstmachines essaie d'exécuter la commande shell
    <c>true</c> sur chaque machine de la liste en exécutant un shell distant.
  </li>
  <li>
    <e>Le répertoire courant est-il disponible sur toutes les
    machines&nbsp;?</e> La commande <c>ls</c> est exécutée dans un shell
    distant pour vérifier la disponibilité d'un fichier créé par tstmachines
    (dans le répertoire courant).
  </li>
  <li>
    <e>Les programmes utilisateurs peuvent-ils être exécutés sur les systèmes
    distants&nbsp;?</e> Ce test vérifie si les bibliothèques partagées et les
    autres composantes ont été installées correctement sur toutes les machines.
  </li>
</ul>

<p>
Bien sûr, n'oublions pas le test classique pour tout outil de
développement&nbsp;:
</p>

<pre caption="Tester un outil de développement">
# <i>cd ~</i>
# <i>cp /usr/share/mpich/examples1/hello++.c ~</i>
# <i>make hello++</i>
# <i>mpirun -machinefile /usr/share/mpich/machines.LINUX -np 1 hello++</i>
</pre>

<p>
Pour plus d'information sur MPICH, consultez la documentation disponible à
l'adresse&nbsp;: <uri
link="http://www-unix.mcs.anl.gov/mpi/mpich/docs/mpichman-chp4/mpichman-chp4.htm">http://www-unix.mcs.anl.gov/mpi/mpich/docs/mpichman-chp4/mpichman-chp4.htm</uri>.
</p>

</body>
</section>
<section>
<title>LAM</title>
<body>

<p>
(Bientôt disponible&nbsp;!)
</p>

</body>
</section>
<section>
<title>OMNI</title>
<body>

<p>
(Bientôt disponible&nbsp;!)
</p>

</body>
</section>
</chapter>

<chapter>
<title>Bibliographie</title>
<section>
<body>

<p>
La version originale de ce document est publiée sur le site Web du <uri
link="http://www.adelielinux.com">Centre de R&amp;D Adelie Linux</uri>. Le
document est reproduit avec la permission des auteurs, du <uri
link="http://www.adelielinux.com">Centre de R&amp;D Adelie Linux</uri> et de
<uri link="http://www.cyberlogic.ca">Cyberlogic</uri>.
</p>

<ul>
  <li><uri>http://www.gentoo.org</uri>, Gentoo Foundation, Inc.</li>
  <li>
    <uri link="http://www.adelielinux.com">http://www.adelielinux.com</uri>,
    Centre de recherche et de développement Adelie Linux.
  </li>
  <li>
    <uri link="http://nfs.sourceforge.net/">http://nfs.sourceforge.net</uri>,
    Linux NFS Project.
  </li>
  <li>
    <uri link="http://www-unix.mcs.anl.gov/mpi/mpich/">http://www-unix.mcs.anl.gov/mpi/mpich/</uri>,
    Mathematics and Computer Science Division, Argonne National Laboratory.
  </li>
  <li>
    <uri link="http://www.ntp.org/">http://ntp.org</uri>
  </li>
  <li>
    <uri link="http://www.eecis.udel.edu/~mills/">http://www.eecis.udel.edu/~mills/</uri>,
    David L. Mills, University of Delaware.
  </li>
  <li>
    <uri link="http://www.ietf.org/html.charters/secsh-charter.html">http://www.ietf.org/html.charters/secsh-charter.html</uri>,
    Secure Shell Working Group, IETF, Internet Society.
  </li>
  <li>
    <uri link="http://www.linuxsecurity.com/">http://www.linuxsecurity.com/</uri>,
    Guardian Digital.
  </li>
  <li>
    <uri link="http://www.openpbs.org/">http://www.openpbs.org/</uri>,
    Altair Grid Technologies, LLC.
  </li>
</ul>

</body>
</section>
</chapter>
</guide>
