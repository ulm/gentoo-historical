<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE sections SYSTEM "/dtd/book.dtd">

<!-- The content of this document is licensed under the CC-BY-SA license -->
<!-- See http://creativecommons.org/licenses/by-sa/2.5 -->

<!-- $Header: /var/cvsroot/gentoo/xml/htdocs/doc/en/handbook/draft/complete/Attic/hb-install-storage.xml,v 1.1 2006/01/06 20:05:07 swift Exp $ -->

<sections>

<version>0.0</version>
<date>2005-06-19</date>

<section>
<title>Storage</title>
<subsection>
<title>Introduction</title>
<body>

<p>
A difficult job of any Linux installation is to prepare the partitions to house
the Operating System. Each person has a different taste as to what should be on
a different partition and what shouldn't, or what file system to use. 
</p>

<p>
The idea behind partitioning is to make some sort of separation between one set
of data and another. For instance, people have their <path>/boot</path>
separated from the root file system because they want to be able to hide the
<path>/boot</path> content from the system during regular operations. Or they
want to have <path>/home</path> separate because that would allow them to store
all user-specific information, settings and data on a different disk so they are
able to easily retrieve the data after an Operating System reinstallation.
</p>

<p>
You can also choose to have a separate partition because you want to improve
performance by using a different file system tweaked to the use of the data
stored on the partition.
</p>

<p>
Deciding on the partition scheme requires intimate knowledge of the file system:
</p>

<ul>
  <li>What files are stored where?</li>
  <li>How often are the files used? Read or written?</li>
  <li>What is the function of the system you are building?</li>
  <li>What features do the various file systems have?</li>
</ul>

<p>
Because this is something that comes with age (err, experience ;) your first,
second, third, ... attempt for a perfect scheme will undoubtedly fail. Lots of
people therefore opt for a simple partitioning scheme (like everything on a
single partition, with a separate partition for the swap<sup>1</sup> 
information). Others attempt to use a more dynamical approach and use 
<e>Volume Management</e>. 
</p>

<p>
With Volume Management, you place a layer in between the partitions on the disk
and the file systems that hold your data. This layer can be used to combine
multiple partitions as if they were just a single one, or to use several logical
divisions on a single partition. Of course, Volume Management is much more than
that: it makes it easier to move data across partitions, shrink or grow file
systems, etc.
</p>

<note>
<sup>1</sup> Swap space is a specific location on the disk where the Linux 
kernel can store memory pages (regions of data in memory, assigned for use by 
processes or by the kernel itself) that will most likely not be used in a while.
The Linux kernel will, once your memory is completely filled (not sooner!), 
move such memory pages to the swap location, thereby freeing internal memory 
for other, more important memory pages.
</note>

</body>
</subsection>
<subsection>
<title>Designing a scheme</title>
<body>

<p>
You should start designing a partitioning scheme for your system. Telling you
what partitioning scheme is best for you is impossible, but here are some
pointers:
</p>

<ul>
  <li>
    For each partition you want to create, ask around how much space the
    partition might get given the tools and services you want to install. Make
    sure you design each partition to be larger than the size given by others:
    growing a file system is <e>not</e> without danger.
  </li>
  <li>
    Not all Linux file system locations are partitionable:
    <ol>
      <li>
        The <path>/etc</path>, <path>/lib</path>, <path>/bin</path> and
        <path>/sbin</path> locations must stay on the root file system as they
        are required by the Operating System under any circumstances. This is
        because they are needed to be able to mount other partitions on the file
        system.
      </li>
      <li>
        Only directories can be separated from a file system. Each separation
        automatically includes all subdirectories.
      </li>
      <li>
        You can not separate two different locations and still store them on a
        single partition (logical, that is - with Volume Management physical
        partitions <e>can</e> hold several logical ones), so you can't put both
        <path>/usr</path> and <path>/opt</path> on a single location.
      </li>
    </ol>
    Some locations also require special attention:
    <ol>
      <li>
        The <path>/dev</path> location will already be separated from the main
        file system by the device manager, so you don't need to devote a
        specific partition for <path>/dev</path>.
      </li>
      <li>
        The <path>/tmp</path> and <path>/var/tmp</path> locations are used for
        temporary file storage. Although the content of these locations is slim
        in most situations, it can grow exponentially. For instance, during the
        installation of software through Portage, <path>/var/tmp/portage</path>
        is used and can require up to a few gigabytes (!) of space.
      </li>
    </ol>
  </li>
  <li>
    Ask yourself if you really need that nifty file system feature: using Volume
    Management or (Software) RAID does require more work. Without much guidance,
    you might lose too much time stabbing at storage related problems.
  </li>
  <li>
    Many backup solutions are file system independant, but some of them aren't.
    If the backup storage is limited but you are using a file system dependant
    solution, make sure that the total amount of data that it will backup
    doesn't exceed the dedicated backup storage size.
  </li>
</ul>

<p>
We will discuss the more advanced storage solutions in more detail in a
different part of this book, but to make you aware of the possibilities we'll
give a quick rundown of those features first. We won't integrate these solutions
with the installation procedure though as that would complicate things too much.
</p>

</body>
</subsection>
<subsection id="raid_arrays">
<title>RAID arrays</title>
<body>

<p>
RAID stands for <e>Redundant Array of Inexpensive Disks</e> and is a well-known
way of putting disks together. There are several RAID levels defined:
</p>

<ul>
  <li>
    <e>RAID-Linear</e> places two (or more) disks next to each other and let the
    user view them as if those disks were a single one. At first, all data is
    written to the first disk. Once that disk is filled, the second disk is
    used, etc.
  </li>
  <li>
    <e>RAID-0</e> is also called <e>striping</e>: unlike with RAID-Linear data
    is first partitioned after which each 'stripe' of data is written to a disk.
    Therefore data written to a RAID-0 array is stored across all disks.
  </li>
  <li>
    <e>RAID-1</e>, also known as <e>mirroring</e>, places all data written to
    the array on <e>all disks</e>. In other words, each member of the RAID-1
    array is an exact copy of the others.
  </li>
  <li>
    <e>RAID-5</e> requires at least three disks. We'll explain its inner
    workings for three disks, but more than three is perfectly possible as well.
    When data is sent to the array, it is partitioned. For each two parts of
    data, a simple <e>checksum</e> is created, so we have three data segments.
    Those three segments are then stored to a disk. If one of the segments is
    lost, it can be retrieved from the other two segments if necessary.
  </li>
</ul>

<p>
Other RAID levels exists but are less frequently used.
</p>

<p>
RAID arrays are interesting when you need high availability of your data. For
instance, with RAID-1, if one of the disks crashes, the other one takes over.
Something similar happens with RAID-5: if one of the disks crashes, the other
disks can work together to generate the data that was stored on the
malfunctioning disk.
</p>

<p>
If you have a true hardware RAID card, using RAID within Linux (or any other
Operating System for that matter) does not require any input at all: the
operating system does not handle anything RAID-related. You only see the result,
the hardware RAID card handles all the rest.
</p>

<p>
Pseudo-hardware RAID cards offer various RAID-related services but still require
some (or a lot) of operating system input. Such cards therefore require a good
working driver and perhaps even a few tools. Although they aren't as transparent
as true hardware RAID cards, they still beat the software RAID.
</p>

<p>
Software RAID allows users to benefit from most of the RAID functionality
without requiring any specific hardware. This does require the operating system
to handle all the RAID-related tasks, requiring some computing time.
</p>

<p>
Information about using Software RAID is discussed further in this book.
</p>

</body>
</subsection>
<subsection>
<title>Logical Volume Management</title>
<body>

<p>
Unlike RAID, which is most often used for redundancy, LVM allows the user to
maximise the flexibility of his storage. Basically LVM (actually, LVM2) should
be seen as a layer in between the physical storage (the disks) and the logical
view (the file system).
</p>

<p>
With LVM, you create <e>logical volumes</e> (partitions) which hold the file 
systems. One or more logical volumes are stored on a <e>volume group</e> which 
is nothing more than a collection of <e>physical volumes</e> (partitions). A
physical volume is an entire disk, or a partition, controller by LVM.
</p>

<p>
The LVM software offers services on top of this intermediate layer. For
instance, you can `spread' data across several partitions (like RAID-Linear or
RAID-0), or have several logical partitions on a single physical one. But that's
not it. LVM allows you to add (or remove) physical volumes from a volume group
without affecting the logical volumes (unless of course the logical volumes
require more space than the volume group has to offer), move data from one disk
to another without requiring any manual copy procedure or take a snapshot of an
entire file system without really having to take a full copy of the system.
</p>

<p>
These (and more) features make LVM a powerful tool of many system
administrators.
</p>

<p>
Information about LVM2 is discussed further in this book.
</p>

</body>
</subsection>
<subsection>
<title>Preparing the devices</title>
<body>

<p>
Before you can start creating the necessary partitions, you need to make sure
that the Linux Operating System can work with your hardware. If the installation
CD that you used to boot didn't automatically detect your hardware, you will
need to load the appropriate support manually.
</p>

<p>
Although we can start by educating you how the Linux kernel addresses the disks
(like <path>/dev/hd*</path> for IDE, <path>/dev/sd*</path> for SCSI and Serial
ATA, ...) and what logic is behind it, we will leave this for another document
(or perhaps a later chapter :) and immediately tell you how to discover where
your disks are.
</p>

<p>
If your disks are SCSI or Serial ATA (although some SATA disks are treated as
native IDE disks, most of them are using a SCSI-like driver), run <c>dmesg</c>
and filter out any occurrence of 'disk'. IDE disk users should filter out 'ide'
and 'hd':
</p>

<pre caption="Finding out what disk(s) you have">
<comment>(For SCSI or SATA:)</comment>
# <i>dmesg | grep -i disk</i>
Attached scsi disk sda at scsi0, channel 0, id 0, lun 0

<comment>(For IDE:)</comment>
# <i>dmesg | grep -i ide | grep -i hd</i>
TODO insert IDE output
</pre>

<p>
In the above example we discover that our SCSI (or SATA) disk is at
<path>/dev/sda</path> and our IDE disks are at TODO. If this does not reflect
the setup you have, you will need to load the appropriate drivers. Otherwise
continue with the next section on <uri link="#raid_arrays">RAID Arrays</uri>.
</p>

<p>
Your Linux system can tell you what controllers you have and what chipset they
use. This information is vital if you need to load additional drivers. The
combination of the <c>lspci</c> tool and the <c>grep</c> filter proves to be
quite efficient.
</p>

<p>
For instance, if you have an IDE controller but it wasn't loaded by default, try
filtering for 'ide'. Similar actions should be performed for Serial ATA ('sata')
or SCSI ('scsi'):
</p>

<pre caption="Findout out what IDE controllers are available on a system">
# <i>lspci | grep -iE '(ide|sata)'</i>
0000:00:1f.1 IDE interface: Intel Corporation 82801FB/FBM/FR/FW/FRW (ICH6 Family) 
  IDE Controller (rev 04)
0000:00:1f.2 Class 0106: Intel Corporation 82801FBM (ICH6M) SATA Controller 
  (rev 04)
</pre>

<p>
Based on this information you can try searching for the appropriate support
drivers. A quick <c>grep</c> on the content of the <path>/lib/modules</path>
directory (which stores all the additional kernel modules):
</p>

<pre caption="Searching for support drivers">
# <i>find /lib/modules | grep -iE '(82801|ich6)'</i>
TODO
</pre>

<p>
If you found a matching kernel module, load it in memory and rediscover where
your disks are:
</p>

<pre caption="Loading the kernel module">
# <i>modprobe TODO</i>
</pre>

</body>
</subsection>
</section>

<section>
<title>Partitioning</title>
<subsection>
<title>Architecture-specific</title>
<body>

<p>
Partitioning is architecture-dependant as partitions are generally tagged for
some function. The <e>type</e> of a distribution is therefore a very important
setting. Two important types are:
</p>

<dl>
  <dt>82 (Linux Swap)</dt>
  <dd>The partition holds swap information</dd>
  <dt>83 (Linux)</dt>
  <dd>The partition holds a Linux file system</dd>
</dl>

<p>
The partition structure is also architecture-dependant. Some architectures only
allow a few partitions (sometimes also called <e>slices</e>) to be available,
others have some weird solution to get over a very narrow limit causing
confusion in the numbering scheme of the partitions. There are even
architectures where certain partition numbers are reserved for a specific use.
</p>

<p>
You will find architecture-specific partitioning information in the first 
Appendix of this book, together with an example partition layout which you can
use to get started with Gentoo Linux.
</p>

</body>
</subsection>
<subsection>
<title>Create them, now!</title>
<body>

<p>
Read the partitioning information for your architecture <e>now</e> and create
the partitions you'll use to store Gentoo Linux on. 
</p>

</body>
</subsection>
</section>

<section>
<title>Filesystems</title>
<subsection>
<title>Overview</title>
<body>

<p>
Partitions alone aren't sufficient to store data (unless the partition for a
specific purpose, like raw access for databases). You need to apply some
structure to the partition so that Linux knows where files and directories are
stored, what permissions are set to the file, what security attributes are
applied, etc.
</p>

<p>
This is the task of the file system. A <e>file system</e> is a standard way of
storing and retrieving information from a partition. It dictates where the files
data is stored and how to get access to the file <e>metadata</e> (everything
about a file except the content, like name, creation date, owner, ...). 
</p>

<p>
Linux supports quite a lot file systems, but not all of them are functional
enough to store Linux files. For instance, the FAT-family (FAT12 for floppies,
FAT16 for small partitions and FAT32 for larger ones) has no concept of
permissions while the NTFS-family (all the dozen versions that Microsoft has
released thus far) is too complex (partially due to its closed-source nature)
and not fully supported.
</p>

<p>
We will describe the most known file systems that you can use to hold your Linux
Operating System together with some information on the tools associated with the
file system.
</p>

</body>
</subsection>
<subsection>
<title>Extended 3</title>
<body>

<p>
Extended 3 is the <e>journaled</e> version of Extended 2, the older (but proven)
file system which is the first real Linux file system ever developed for Linux
(before ext2, the Minix file system was used - but that was a long, long time
ago). Extended 3 is currently the most used file system as well.
</p>

<p>
As a <e>journaled</e> file system, ext3 can make sure that the entire file
system is consistent at any time. In other words, if your system would ever
crash (for instance due to a power interruption), the file system would never
contain garbled data - if you were busy writing data to the disk, either the old
data is there, or the new data, but not a partial write.
</p>

<p>
You can choose between no journaling (which basically means that the file system
should be seen a an Extended 2), metadata journaling (where only the metadata is
consistent across time) where you can choose between writeback (first metadata
write, then data) and ordered (first data write, then metadata) and full
journaling. The ordered metadata journaling is the default.
</p>

<p>
Extended 3 supports access control lists and is therefore a candidate file
system for more security enhanced Linux kernels who require ACLs to be available
for the file system.
</p>

<p>
To write an ext3 file system on a device, use the <c>mke2fs</c> tool with the
<c>-j</c> option (for <e>journaling</e>):
</p>

<pre caption="Writing an ext3 file system on /dev/hda3">
# <i>mke2fs -j /dev/hda3</i>
</pre>

<p>
The <c>mke2fs</c> command has a few interesting options as well:
</p>

<ul>
  <li>
    Writing a file system to the disk is quite fast. If you want to check the 
    device for bad blocks during the file system write, add a <c>-c</c> option.
    If you specify this option twice, a full read-write test is performed 
    instead of a read-only test.
  </li>
  <li>
    To speed up lookups in large directories, you can enable directory indexing
    by adding <c>-O dir_index</c>. 
  </li>
  <li>
    Large file systems might free more space by adding <c>-O sparse_super</c>.
    This will decrease the percentage of blocks used as backups for the file
    metadata.
  </li>
</ul>
    
</body>
</subsection>
<subsection>
<title>The swap file system</title>
<body>

<p>
Although you can't 'use' the swap space directly, it does use a specific file
system to store the memory pages. To create a swap file system on the swap
partition, use <c>mkswap</c>:
</p>

<pre caption="Creating a swap file system on /dev/hda2">
# <i>mkswap /dev/hda2</i>
</pre>

<p>
Unlike the other file system creation tools, <c>mkswap</c> hardly takes
additional options for tuning purposes.
</p>

</body>
</subsection>
<subsection>
<title>Create the file systems</title>
<body>

<p>
Create the file systems on your partitions <e>now</e> and don't forget to create
the swap file system as well.
</p>

</body>
</subsection>
</section>

<section>
<title>Getting in the minimal environment</title>
<subsection>
<title>Mounting the partitions</title>
<body>

<p>
The next step is to <e>mount</e> the file systems in the Linux file system
hierarchy so that you can use it. As we have said in the previous part, mounting
attaches the file system to the current hierarchy at a specified location.
</p>

<p>
On the Gentoo installation CD, a directory <path>/mnt/gentoo</path> is available
to mount your root file system in spe. Let us suppose that the file system is at
<path>/dev/hda3</path>, then the <c>mount</c> command would be:
</p>

<pre caption="Mounting the root file system at /mnt/gentoo">
# <i>mount /dev/hda3 /mnt/gentoo</i>
</pre>

<p>
You'll also need to mount the other file systems at the correct place. Because
your root file system doesn't contain any directories yet, you'll need to create
them. For instance, if you have a separate <path>/boot</path> (at
<path>/dev/hda1</path> and <path>/usr</path> (at <path>/dev/hda4</path>) file 
system:
</p>

<pre caption="Creating mount points prior to mounting the file systems">
# <i>mkdir /mnt/gentoo/boot /mnt/gentoo/usr</i>
# <i>mount /dev/hda4 /mnt/gentoo/usr</i>
# <i>mount /dev/hda1 /mnt/gentoo/boot</i>
</pre>

<p>
You will also need to activate the swap partition. This is accomplished using
the <c>swapon</c> command:
</p>

<pre caption="Activating the swap space">
<comment>(Example for a swap file system at /dev/hda2)</comment>
# <i>swapon /dev/hda2</i>
</pre>

</body>
</subsection>
<subsection>
<title>Preparing the stage tarball</title>
<body>

<p>
A Gentoo stage tarball contains a minimal Gentoo environment. If you are booted
from a Gentoo universal installation CD you might find the stage of your choice
on the CD (probably at <path>/mnt/cdrom/stages</path>). If not, you can download
one from one of our <uri
link="http://www.gentoo.org/main/en/mirrors.xml">mirrors</uri>. They are stored
in the appropriate release directory under the name <path>stages/</path>.
</p>

<p>
A <e>tarball</e> is an archive, usually compressed using Lempel-Ziv coding
(LZ77 - <c>gzip</c>) or Burrows-Wheeler compression with Huffman coding
(<c>bzip2</c>). Uncompressed, you will have a single file (a tar<sup>2</sup> 
file) that contains all the files in the archive, nicely appended one after 
another.
</p>

<p>
To download such a stage tarball, <e>first</e> go to <path>/mnt/gentoo</path>.
This is required so that, once you start downloading the file, it is stored on
the disk and not in memory (the Gentoo installation CD creates a virtual 'disk'
in memory so that you can use the CD without requiring any pre-installed Linux
system).
</p>

<pre caption="Downloading a stage tarball">
# <i>cd /mnt/gentoo</i>
# <i>lynx http://www.gentoo.org/main/en/mirrors.xml</i>
</pre>

<p>
Next, extract the tarball to the <path>/mnt/gentoo</path> location. Use the
<c>tar</c> tool with <c>xjpf</c> as options and the tarball as argument:
</p>

<ul>
  <li>e<b>x</b>tract the files from the archive</li>
  <li>
    use <c>bunzip2</c> to decompress the archive (<b>j</b> due to shortage of
    available options :)
  </li>
  <li><b>p</b>reserve the permissions that were stored in the tarball</li>
  <li>use the next <b>f</b>ile as the archive</li>
</ul>

<pre caption="Extracting the stage tarball">
# <i>tar xjpf &lt;file&gt;</i>
</pre>

<p>
If your stage tarball is stored on the CD, just use the path to the file for
<path>&lt;file&gt;</path>.
</p>

<note>
<sup>2</sup>: the name <e>tar</e> comes from Tape ARchive. The <c>tar</c> tool
was (and still is) commonly used for backing up files to tapes which only have
linear access (unlike digital media where you can quickly jump from one location
to another). Because of this limitation, all files are aligned after another
with a table of contents stored in the beginning of the tape. The <c>tar</c>
tool is still a very popular tool for creating archives.
</note>

</body>
</subsection>
<subsection>
<title>Extracting a Portage snapshot</title>
<body>

<p>
We need to extract another tarball, namely a <e>portage snapshot</e>. Portage is
the software management system Gentoo uses. The package information itself is
stored in what we call the <e>Portage tree</e>. A <e>portage snapshot</e>
is a Portage tree taken at a certain point in time. 
</p>

<p>
On a universal installation CD, you might find such a snapshot at
<path>/mnt/gentoo/snapshot</path>, but you can always download a snapshot from
the Internet as well. Go to one of our <uri
link="http://www.gentoo.org/main/en/mirrors.xml">mirrors</uri> and locate the
most recent portage snapshot in the <path>snapshots/</path> directory.
</p>

<pre caption="Downloading a Portage tree snapshot">
# <i>lynx http://www.gentoo.org/main/en/mirrors.xml</i>
</pre>

<p>
We don't need any specific permission information from the snapshot, so the
<c>tar</c> command only requires <c>xjf</c> as options. However, the snapshot
<e>must</e> be extracted inside <path>/mnt/gentoo/usr</path>. We could do the
same as we did with the stage tarball and first go to
<path>/mnt/gentoo/usr</path> before we run the extraction command, but you can
also use <c>-C &lt;location&gt;</c> (with a capital C) to inform <c>tar</c> that
the <path>/mnt/gentoo/usr</path> location is the destination:
</p>

<pre caption="Extracting a Portage tree snapshot">
# <i>tar xjf &lt;snapshot&gt; -C /mnt/gentoo/usr</i>
</pre>

</body>
</subsection>
<subsection>
<title>Preparing the minimal Gentoo environment</title>
<body>

<p>
As you might have guessed already, we are trying to have 
<path>/mnt/gentoo</path> contain a fully functional Linux environment. To finish
this off, we need to mount a specific <e>pseudo file system</e> called proc at
<path>/mnt/gentoo/proc</path>. This is not a file system stored on a disk, but
rather an interface to the Linux kernel showing kernel information as regular
files. This allows you to retrieve kernel (and system) information by just
reading files instead of requiring specific tools.
</p>

<pre caption="Mounting the proc file system">
# <i>mount -t proc none /mnt/gentoo/proc</i>
</pre>

<p>
To be able to use the network you have defined (if applicable), you need to copy
over the <path>/etc/resolv.conf</path> file to the new Linux environment:
</p>

<pre caption="Copying over the name resolving information file">
# <i>cp /etc/resolv.conf /mnt/gentoo/etc</i>
</pre>

</body>
</subsection>
<subsection>
<title>Changing the root from CD to the new environment</title>
<body>

<p>
The final step now is to change the root of your file system from the one
provided by the CD to the one you just set up, namely <path>/mnt/gentoo</path>.
Using the <c>chroot</c> tool, your terminal session will not see anything
outside <path>/mnt/gentoo</path> unless you finish the <c>chroot</c> itself.
Because you need a shell to navigate, we run <path>/bin/bash</path> (the Bourn
Again SHell) right after changing the root:
</p>

<pre caption="Changing the root to /mnt/gentoo">
# <i>chroot /mnt/gentoo /bin/bash</i>
</pre>

</body>
</subsection>
</section>

</sections>
