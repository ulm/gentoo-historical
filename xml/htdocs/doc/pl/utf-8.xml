<?xml version='1.0' encoding="UTF-8"?>
<!DOCTYPE guide SYSTEM "/dtd/guide.dtd">
<!-- $Header: /var/cvsroot/gentoo/xml/htdocs/doc/pl/utf-8.xml,v 1.9 2006/02/12 02:10:07 shadoww Exp $ -->

<guide link="/doc/pl/utf-8.xml" lang="pl">
<title>Kodowanie UTF-8 w Gentoo</title>

<author title="Autor">
  <mail link="slarti@gentoo.org">Thomas Martin</mail>
</author>
<author title="Redaktor">
  <mail link="devil@gentoo.org.ua">Alexander Simonov</mail>
</author>
<author title="Redaktor">
  <mail link="fox2mike@gentoo.org">Shyam Mani</mail>
</author>
<author>
  Aleksander Kamil Modzelewski
</author>

<abstract>
Ten podręcznik pokazuje jak skonfigurować i wykorzystać kodowanie znaków UTF-8 w
systemie Gentoo Linux oraz omawia korzyści z wykorzystania Unikodu, a w
szczególności UTF-8.
</abstract>

<!-- The content of this document is licensed under the CC-BY-SA license -->
<!-- See http://creativecommons.org/licenses/by-sa/2.5 -->
<license />

<version>2.17</version>
<date>2006-02-11</date>

<chapter>
<title>Kodowanie znaków</title>
<section>
<title>Czym jest kodowanie znaków?</title>
<body>

<p>
Komputery nie rozumieją tekstu wprost. Zamiast tego każdy znak reprezentowany
jest przez liczbę. Tradycyjnie każdy zestaw liczb wykorzystywany do
reprezentacji alfabetów oraz znaków (znany jako system kodowania (ang.  coding
system), kodowanie (encoding) lub zestaw znaków (character set) był ograniczony
w rozmiarze w wyniku ograniczeń sprzętowych.
</p>

</body>
</section>
<section>
<title>Historia kodowania znaków</title>
<body>

<p>
Najpopularniejszym (a w każdym bądź razie najpowszechniej przyjętym) zestawem
jest <b>ASCII</b> (American Standard Code for Information Interchange -
Amerykański Standardowy Kod dla Wymiany Informacji). Powszechnie uważa się, że
ASCII jest najskuteczniejszym standardem w oprogramowaniu. Współczesny ASCII
został przyjęty w roku 1986 (ANSI X3.4, RFC 20, ISO/IEC 646:1991, ECMA-6) przez
Amerykański Narodowy Instytut Standardów (ang. American National Standards
Institute).
</p>

<p>
ASCII jest kodowaniem ściśle siedmiobitowym - to znaczy wykorzystującym liczby,
które da się zapisać na siedmiu bitach, co daje zakres od 0 do 127
(dziesiątkowo). Wśród tych 128 znaków zawarte jest 32 znaki niedrukowalne, w
większości zawarte między 0 i 31, oraz znak DEL (czyli skasuj, ang. delete) na
pozycji 127. Znaki od 32 do 126 to znaki drukowalne: spacja, znaki przestankowe,
litery łacińskie oraz cyfry.
</p>

<p>
Pierwotnie ósmy znak ASCII wykorzystywany był jako bit parzystości dla kontroli
błędów. Jeśli nie było to potrzebne, pozostawiano go jako 0. To znaczy, że w
ASCII każdy znak reprezentowany jest przez dokładnie jeden bajt.
</p>

<p>
Chociaż ASCII było wystarczające dla komunikacji w nowoczesnym angielskim, w
innych językach europejskich, w których występowały znaki akcentowane, nie było
to już takie proste. Standardy ISO 8859 zostały opracowane, aby sprostać temu
problemowi. Były one zgodne z ASCII, ale zamiast pozostawiać ostatni bit pustym,
wykorzystywały go, aby dopuścić dodatkowe 127 znaków w każdym kodowaniu.
Niestety ograniczenia ISO 8859 stały się szybko widoczne i w chwili obecnej
istnieje 15 wariantów tego standardu (od 8859-1 do 8859-15). Poza zakresem
zgodnym z ASCII często występują konflikty pomiędzy znakami reprezentowanymi
przez każdy bajt.  Dodatkową komplikacją jest fakt, że niektóre wersje systemu
Microsoft Windows wykorzystują standard Windows-1252 (dla wersji polskiej -
Windows-1250).  Jest to nadzbiór ISO 8859-1 (Windows-1250 jest podobny do ISO
8859-2), jest jednak na parę sposobów odmienny. Wszystkie tet zbiory zachowują
jednak zgodność z ASCII.
</p>

<p>
Niezbędne okazało się też wprowadzenie całkowicie odmiennych kodowań dla
alfabetów innych niż łacińskie, takich jak EUC (Extended Unix Coding -
Rozszerzone Kodowanie Uniksowe), który jest wykorzystywane w językach Japońskim
i Koreańskim (oraz, w ograniczonym zakresie, w Chińskim) - co wprowadziło
dodatkowe zamieszanie. Tymczasem inne systemy operacyjne wykorzystywały jeszcze
inne kodowania dla tych samych języków, jak na przykład Shift-JIS czy
ISO-2022-JP. Użytkownicy chcący oglądać znaki Cyrylicy musieli wybierać pomiędzy
KOI8-R dla Rosyjskiego i Bułgarskiego, KOI8-U dla Ukraińskiego oraz innych
kodowań Cyrylicy, takich jak nieudany ISO 8859-5 oraz popularny Windows-1251.
Wszystkie te kodowania łamały kompatybilność z ASCII (aczkolwiek kodowania KOI8
ustawiają znaki cyrylicy w kolejności Łacińskiej, więc po odcięciu ósmego bitu
tekst da się odczytać przez tzw. <e>case-reversed transliteration</e>.
</p>

<p>
Powstało w ten sposób zamieszanie niemal całkowicie uniemożliwiające komunikację
wielojęzykową - szczególnie pomiędzy odmiennymi alfabetami. Problem ten
rozwiązać ma Unikod.
</p>

</body>
</section>
<section>
<title>Czym jest Unikod?</title>
<body>

<p>
Unikod odrzuca tradycyjne ograniczenie kodowań jednobajtowych. Wykorzystuje 17
"płaszczyzn" po 65 536 znaków do opisu maksymalnie 1 114 112 znaków. Ponieważ
pierwsza płaszczyzna, znana jako "Podstawowa Płaszczyzna Wielojęzykowa" (ang.
BMP - Basic Multilangual Plane) zawiera niemal wszystko, co typowy użytkownik
kiedykolwiek wykorzysta, wiele osób przyjmuje fałszywe założenie, że Unikod jest
zbiorem 16-bitowym.
</p>

<p>
Unikod jest mapowany na wiele różnych sposobów, ale dwa najpopularniejsze to
<b>UTF</b> (Unicode Transformation Format - Format Transformacji Unikodu) oraz
<b>UCS</b> (Universal Character Set - Uniwersalny Zestaw Znaków). Numer za UTF
oznacza liczbę bitów w jednej jednostce, natomiast numer za UCS oznacza liczbę
bajtów. UTF-8 stał się najpopularniejszą formą wymiany tekstu w Unikodzie dzięki
swojej zgodnej z kodowaniami 8-bitowymi naturze. Dlatego właśnie jemu poświęcony
jest ten dokument.
</p>

</body>
</section>
<section>
<title>UTF-8</title>
<body>

<p>
UTF-8 jest kodowaniem o zmiennej długości znaku - to znaczy że każdy znak może
być opisany przez od jednego do czterech bajtów. Tak więc pierwszy bajt UTF-8
wykorzystywany jest do kodowania ASCII, dzięki czemu jest on w pełni zgodny z
ASCII. Znaki ASCII oraz Łacińskie daje się kodować z niewielką nadmiarowością,
ponieważ wykorzystany jest tylko pierwszy bit. Użytkownicy alfabetów wschodnich,
takich jak japoński, którym przyznano wyższy zakres są niezadowoleni, ponieważ
nadmiarowość osiąga nawet 50% dla ich danych.
</p>

</body>
</section>
<section>
<title>Jakie korzyści daje UTF-8?</title>
<body>

<p>
UTF-8 pozwala na pracę w zgodnym ze standardami i akceptowanym międzynarodowo
środowisku wielojęzycznym przy stosunkowo niewielkiej nadmiarowości. UTF-8 jest
najlepszym sposobem przekazywania znaków spoza ASCII przez Internet - dla
poczty, IRC lub prawie każdego innego medium. Pomimo tego wiele osób uważa
wykorzystanie UTF-8 w komunikacji on-line za nadużycie. Dobrze jest być
świadomym nastawienia społeczności danego kanału, listy mailingowej, czy grupy
usenetowej przed wykorzystaniem <e>niezgodnej z ASCII</e> części UTF-8.
</p>

</body>
</section>
</chapter>

<chapter>
<title>Konfiguracja UTF-8 w Gentoo Linux</title>
<section>
<title>Znajdowanie lub tworzenie lokalizacji UTF-8</title>
<body>

<p>
Teraz, gdy znamy już zasadę działania Unikodu, możemy przystąpić do
wykorzystania go w systemie.
</p>

<p>
Wstępnym wymaganiem dla UTF-8 jest wersja glibc ze wsparciem dla języków
narodowych (ang. NLS, National Language Support). Zalecanym sposobem uzyskania
tego jest plik <path>/etc/locales.build</path> w połączeniu z flagą USE
<c>userlocales</c>.  Wykorzystanie tego pliku jest poza zakresem tego dokumentu,
ale jest on na szczęście dobrze udokumentowany w komentarzach w nim zawartych.
Jest też opisany w tekście zatytułowanym <uri
link="/doc/pl/guide-localization.xml#doc_chap3_sect3">Lokalizacja Gentoo Linux
</uri>.
</p>

<p>
Następnie należy określić czy lokalizacja UTF-8 jest już dostępna dla wybranego
języka czy też należy ją utworzyć.
</p>

<pre caption="Sprawdzanie dostępności lokalizacji UTF-8">
<comment>("pl_PL" należy zastąpić nazwą oczekiwanej lokalizacji)</comment>
# <i>locale -a | grep 'pl_PL'</i>
pl_PL
pl_PL.UTF-8
</pre>

<p>
Z wyjścia tego polecenia należy wybrać wynik z końcówką <c>.UTF-8</c>. Jeśli
żaden z wierszy nie ma takiej końcówki to musimy utworzyć lokalizację zgodną z
UTF-8.
</p>

<note>
Poniższe polecenie należy wywołać tylko wtedy, gdy nie jest dostępna lokalizacja
zgodna z UTF-8 dla wybranego języka.
</note>

<pre caption="Tworzenie lokalizacji UTF-8">
<comment>("pl_PL" należy zamienić na oczekiwaną lokalizację)</comment>
# <i>localedef -i pl_PL -f UTF-8 pl_PL.UTF-8</i>
</pre>

<p>
Innym sposobem uzyskania lokalizacji UTF-8 jest dodanie jej do pliku
<path>/etc/locales.build</path> oraz przebudowanie <c>glibc</c> z ustawioną
flagą USE <c>userlocales</c>
</p>

<pre caption="Wiersz w /etc/locales.build">
pl_PL.UTF-8/UTF-8
</pre>

</body>
</section>
<section>
<title>Wybór lokalizacji</title>
<body>

<p>
Zmienna środowiskowa <c>LC_ALL</c> musi być ustawiona, aby wybrać lokalizację
UTF-8 więcej przy lokalizacjach.(ustawienie tej zmiennej powoduje ignorowanie
<c>LANG</c>). Można to zrobić na wiele sposobów; niektórzy preferują kiedy UTF-8
działa tylko dla konkretnego użytkownika - w takim wypadku należy ją ustawić w
pliku <path>~/.profile</path> (jeżeli używa <c>/bin/sh</c>),
<path>~/.bash_profile</path> lub <path>~/.bashrc</path> (jeśli używa
<c>/bin/bash</c>).
</p>

<p>
Inni wolą rozwiązanie globalne. Konkretnym przypadkiem w którym autor sugeruje
takie rozwiązanie jest sytuacja, gdy wykorzystany jest
<path>/etc/init.d/xdm</path>, ponieważ skrypt ten uruchamia menedżer logowania
oraz pulpit zanim którykolwiek z plików zostanie odczytany, a tym samym
zanim którakolwiek ze zmiennych w nim wymienionych znajdzie się w środowisku.
</p>

<p>
Globalną lokalizację powinno się konfigurować zatem użyciem pliku
<path>/etc/env.d/02locale</path>. Plik ten powinien wyglądać podobnie do tego:
</p>

<pre caption="Przykładowy /etc/env.d/02locale">
<comment>(Jak zwykle, "pl_PL.UTF-8" zamieniamy na właściwą lokalizację, jeśli ma być inna niż polska)</comment>
LC_ALL="pl_PL.UTF-8"
</pre>

<p>
Następnie środowisko musi zostać zaktualizowane.
</p>

<pre caption="Aktualizacja środowiska">
# <i>env-update</i>
>>> Regenerating /etc/ld.so.cache...
 * Caching service dependencies ...
# <i>source /etc/profile</i>
</pre>

<p>
Teraz proszę uruchomić <c>locale</c> bez żadnych parametrów aby sprawdzić, czy
właściwe zmienne znajdują się w środowisku:
</p>

<pre caption="Sprawdzanie, czy nowa lokalizacja znajduje się w środowisku">
# <i>locale</i>
LANG=
LC_CTYPE="pl_PL.UTF-8"
LC_NUMERIC="pl_PL.UTF-8"
LC_TIME="pl_PL.UTF-8"
LC_COLLATE="pl_PL.UTF-8"
LC_MONETARY="pl_PL.UTF-8"
LC_MESSAGES="pl_PL.UTF-8"
LC_PAPER="pl_PL.UTF-8"
LC_NAME="pl_PL.UTF-8"
LC_ADDRESS="pl_PL.UTF-8"
LC_TELEPHONE="pl_PL.UTF-8"
LC_MEASUREMENT="pl_PL.UTF-8"
LC_IDENTIFICATION="pl_PL.UTF-8"
LC_ALL=pl_PL.UTF-8
</pre>

<p>
To wszystko. Lokalizacje UTF-8 jest już w użyciu, następnym problemem jest
skonfigurowanie potrzebnych aplikacji.
</p>

</body>
</section>
</chapter>

<chapter>
<title>Wsparcie w aplikacjach</title>
<section>
<body>

<p>
Kiedy Unikod zaczynał zdobywać popularność kodowania wielobitowe nie były dobrze
wspierane przez języki programowania takie jak C, w których napisane jest wiele
popularnych programów. Nawet teraz niektóre programy nie potrafią prawidłowo
obsłużyć UTF-8. Na szczęście większość potrafi!
</p>

</body>
</section>
<section>
<title>Nazwy plików, NTFS oraz FAT</title>
<body>

<p>
W konfiguracji jądra jest kilka opcji NLS i istotnym jest, aby się nie pogubić.
Najważniejszym jest, aby pamiętać o wbudowaniu NLS UTF-8 w jądro i
skonfigurowaniu domyślnego NLS na utf8.
</p>

<pre caption="Konfiguracja UTF-8 w jądrze">
File Systems --&gt;
  Native Language Support --&gt;
    (utf8) Default NLS Option
    &lt;*&gt; NLS UTF8
    <comment>(&lt;*&gt; również dla innych zestawów znaków które będą
    wykorzystywane na systemach plików FAT lub CD-ROM-ach zgodnych z Joliet).
    </comment>
</pre>

<p>
Jeśli planowane jest montowanie partycji NTFS, koniecznym może okazać się
określenie opcji <c>nls=</c> podczas montowania. Przy montowaniu partycji FAT
potrzebne może okazać się określenie opcji <c>codepage=</c>. Opcjonalnie można
ustawić domyślną stronę kodową dla FAT w konfiguracji jądra. Opcja
<c>codepage</c> przy montowaniu jest bardziej znacząca od ustawienia w jądrze.
</p>

<pre caption="Ustawienia FAT w konfiguracji jądra">
File Systems --&gt;
  DOS/FAT/NT Filesystems  --&gt;
    (437) Default codepage for fat
</pre>

<p>
Nie należy ustawiać opcji <c>Default iocharset for fat</c> na UTF-8,
ponieważ może to sprawiać problemy. W zamian lepiej jest przekazywać do
mount opcję utf8=true przy montowaniu partycji FAT. Dalsze informacje można
znaleźć w <c>man mount</c> oraz w dokumentacji jądra w
<path>/usr/src/linux/Documentation/filesystems/vfat.txt</path>.
</p>

<p>
Do zmiany kodowania nazw plików można wykorzystać <c>app-text/convmv</c>.
</p>

<pre caption="Przykładowe wykorzystanie convmv">
# <i>emerge --ask app-text/convmv</i>
<comment>(Składnia polecenia)</comment>
# <i>convmv -f &lt;aktualne-kodowanie&gt; -t utf-8 &lt;nazwa-pliku&gt;</i>
<comment>(iso-8859-2 należy zastąpić oryginalnym kodowaniem)</comment>
# <i>convmv -f iso-8859-2 -t utf-8 nazwa-pliku</i>
</pre>

<p>
Do zmiany <e>zawartości</e> plików można użyć narzędzia <c>iconv</c>,
dostarczanego razem z <c>glibc</c>:
</p>

<pre caption="Przykładowe wykorzystanie iconv">
<comment>(iso-8859-2 należy zastąpić oryginalnym kodowaniem)</comment>
<comment>(Sprawdzenie, czy wyjście jest prawidłowe)</comment>
# <i>iconv -f iso-8859-2 -t utf-8 nazwa-pliku</i>
<comment>(Konwersja pliku, trzeba utworzyć inny plik)</comment>
# <i>iconv -f iso-8859-2 -t utf-8 nazwa-pliku > nowy-plik</i>
</pre>

<p>
<c>app-text/recode</c> też może być wykorzystany do tego celu.
</p>

</body>
</section>
<section>
<title>Konsola systemowa</title>
<body>

<impo>
Do obsługi Unikodu na konsoli potrzebny jest sys-apps/baselayout-1.11.9 lub
nowszy.
</impo>

<p>
Aby wykorzystać UTF-8 na konsoli należy wyedytować <path>/etc/rc.conf</path> i
ustawić <c>UNICODE="yes"</c> oraz przeczytać komentarze w tym pliku.
Wykorzystanie fontu z właściwym zakresem znaków jest istotne jeżeli chce się
wykorzystać jak najwięcej z możliwości Unikodu.
</p>

<p>
Zmienna <c>KEYMAP</c>, ustawiana w <path>/etc/conf.d/keymaps</path>, powinna
wybierać mapę klawiatury zgodną z Unikodem.
</p>

<pre caption="Przykładowy fragment /etc/conf.d/keymaps">
<comment>("pl" należy zamienić na lokalny układ jeśli ma być inny niż polski)</comment>
KEYMAP="pl"
</pre>

<note>
(od tłumaczy) Niektórzy zapewne wolą użyć tu opcji <c>pl2</c>, spowoduje to, że
lewy alt nie będzie zachowywał się jak prawy i będzie go można wykorzystać do
innych funkcji niż tylko pisanie polskich literek. Wiele osób korzysta z opcji
<c>-u</c>. W nowszym baselayout nie jest już konieczne i może powodować
problemy. W związku z tym zalecamy zrezygnowanie z wpisów w stylu <c>-u pl</c>.
</note>

</body>
</section>
<section>
<title>Ncurses oraz Slang</title>
<body>

<note>
Jeśli nie korzysta się ze Slang to można zignorować tę część tekstu.
</note>

<p>
Rozsądnie jest dodać <c>unicode</c> do globalnych flag USE w
<path>/etc/make.conf</path>, a następnie ponownie zainstalować
<c>sys-libs/ncurses</c> oraz <c>sys-libs/slang</c>.
</p>

<pre caption="Emergowanie ncurses oraz slang">
# <i>emerge --update --deep --newuse world</i>
</pre>

<p>
Po zmianie flag USE należy też przebudować pakiety które są z nimi zlinkowane.
Narzędzie które wykorzystamy (<c>revdep-rebuild</c>) jest częścią pakietu
<c>gentoolkit</c>.
</p>

<pre caption="Przebudowanie programów zlinkowanych z ncurses lub slang">
# <i>revdep-rebuild --soname libncurses.so.5</i>
# <i>revdep-rebuild --soname libslang.so.1</i>
</pre>

</body>
</section>
<section>
<title>KDE, GNOME oraz Xfce</title>
<body>

<p>
Wszystkie popularne środowiska użytkownika mają pełne wsparcie dla Unikodu i nie
będą wymagały dalszej konfiguracji poza tym, co już zostało opisane. Wynika to z
tego, że biblioteki graficzne które są ich podstawą (Qt oraz GTK+2) mają
wsparcie dla UTF-8. W rezultacie wszystkie aplikacje bazujące na tych
bibliotekach powinny być zgodne z UTF-8.
</p>

<p>
Wyjątkami od tej zasady są biblioteki Xlib oraz GTK+1. GTK+1 wymaga ustawienia
FontSpec iso-10646-1 w pliku ~/.gtkrc, na przykład
<c>-misc-fixed-*-*-*-*-*-*-*-*-*-*-iso10646-1</c>. Aplikacje wykorzystujące Xlib
lub Xaw również wymagają podobnego FontSpec, w przeciwynm wypadku będą działały
nieprawidłowo.
</p>

<note>
Jeśli dostępne jest centrum sterowania gnome1 to należy w zamian skorzystać z
niego. Wystarczy wybrać w nim dowolny font iso10646-1.
</note>

<pre caption="Przykładowy ~/.gtkrc (dla GTK+1) który wybiera font zgodny z Unikodem">
style "user-font"
{
    fontset="-misc-fixed-*-*-*-*-*-*-*-*-*-*-iso10646-1"
}
widget_class "*" style "user-font"
</pre>

<p>
Jeżeli aplikacja ma wsparcie dla GUI opartego zarówno na QT jak i GTK+2, to
wersja GTK+2 z reguły daje lepsze rezultaty dla Unikodu.
</p>

</body>
</section>
<section>
<title>X11 oraz fonty</title>
<body>

<impo>
<c>x11-base/xorg-x11</c> ma znacznie lepsze wsparcie dla Unikodu niż Xfree86 i
jest <e>bardzo</e> zalecane.
</impo>

<p>
Fonty TrueType mają wsparcie dla Unikodu, podobnie większość fontów
rozpowszechnianych razem z Xorg ma bardzo obszerne (choć nadal niekompletne)
zbiory znaków. Aby zbudować fonty (włączając w to zestaw Bitstream Vera) ze
wsparciem dla znaków Wschodnio-Azjatyckich w X należy upewnić się, że
ustawiona jest flaga USE <c>cjk</c>. Wiele innych aplikacji wykorzystuje tę
flagę więc w zasadzie warto jest ją ustawić globalnie.
</p>

<p>
Również część pakietów fontów dostępnych w Portage ma wsparcie dla Unikodu.
</p>

<pre caption="Opcjonalnie: instalacja dodatkowych fontów wspierających Unikod">
# <i>emerge terminus-font intlfonts freefonts cronyx-fonts corefonts</i>
</pre>

</body>
</section>
<section>
<title>Menedżery okien oraz emulatory terminali</title>
<body>

<p>
Menedżery okien, które nie są oparte na GTK lub Qt z reguły mają bardzo dobre
wsparcie dla Unikodu gdyż często wykorzystują do obsługi czcionek bibliotekę
Xft. Jeżeli wybrany menedżer okien nie wykorzystuje Xft to nadal można
wykorzystać wspomniane wcześniej ustawienie FontSpec.
</p>

<p>
Emulatory terminala, które wykorzystują Xft i wspierają Unikod są trudniejsze do
znalezienia. Poza Konsole i gnome-terminal, najlepszymi wariantami dostępnymi w
Portage są <c>x11-terms/rxvt-unicode</c>, <c>xfce-extra/terminal</c>,
<c>gnustep-apps/terminal</c>, <c>x11-terms/mlterm</c>, lub zwykły 
<c>x11-terms/xterm</c>, kiedy zostanie zbudowany z flagą USE <c>unicode</c> 
oraz wywołany jako <c>uxterm</c>. <c>app-misc/screen</c> również wspiera UTF-8 
o ile zostanie wywołany jako <c>screen -U</c> oraz w <path>~/.screenrc</path> 
znajduje się co następuje:
</p>

<pre caption="~/.screenrc dla UTF-8">
defutf8 on
</pre>

</body>
</section>
<section>
<title>Vim, Emacs, Xemacs oraz Nano</title>
<body>

<p>
Vim ma pełne wsparcie UTF-8 oraz wbudowane rozpoznanie zakodowanych w nim
plików. Dalsze informacje można znaleźć po wykonaniu w Vimie polecenia <c>:help
mbyte.txt</c>.
</p>

<p>
Emacs 22.x oraz nowsze również mają pełne wsparcie dla UTF-8. Xemacs 22.x nie ma
jeszcze wsparcia dla znaków kombinowanych.
</p>

<p>
Starsze wersje Emacsa oraz Xemacsa mogą wymagać instalacji
<c>app-emacs/mule-ucs</c> oraz <c>app-xemacs/mule-ucs</c> oraz modyfikacji
<path>~/.emacs</path> dla uzyskania wsparcia języków CJK w UTF-8:
</p>

<pre caption="Emacs ze wsparciem CJK UTF-8">
(require 'un-define)
(require 'jisx0213)
(set-language-environment "Japanese")
(set-default-coding-systems 'utf-8)
(set-terminal-coding-system 'utf-8)
</pre>

<p>
Nano aktualnie nie wspiera UTF-8, aczkolwiek jest ono od dawna planowane. Przy
odrobie szczęścia w przyszłości sytuacja ulegnie zmianie. W czasie pisania tego
dokumentu wsparcie dla UTF-8 jest w CVS Nano i powinno być umieszczone w
kolejnej edycji.
</p>

</body>
</section>
<section>
<title>Powłoki</title>
<body>

<p>
Już teraz <c>bash</c> zapewnia pełne wsparcie Unikodu za pośrednictwem
biblioteki GNU readline. Użytkownicy powłoki Z są w gorszej sytuacji -- powłoka
ta wcale nie obsługuje Unikodu, aczkolwiek podejmowane są zdecydowane próby
zapewnienia wsparcia dla wielobajtowych zestawów znaków.
</p>

<p>
Powłoki C, <c>tcsh</c> oraz <c>ksh</c> nie zapewniają żadnego wsparcia dla
UTF-8.
</p>

</body>
</section>
<section>
<title>Irssi</title>
<body>

<p>
Irssi ma pełne wsparcie dla UTF-8, wymaga tylko ustawienia opcji przez
użytkownika.
</p>

<pre caption="Uruchamianie UTF-8 w Irssi">
/set term_type UTF-8
</pre>

<p>
Na kanałach w których znaki spoza ASCII nie są wymieniane w UTF-8 polecenie
<c>/recode</c> może zostać użyte do konwersji znaków. Więcej informacji będzie
dostępne po wpisaniu polecenia <c>/help recode</c>.
</p>

</body>
</section>
<section>
<title>Mutt</title>
<body>

<p>
Klient poczty Mutt ma bardzo dobre wsparcie dla Unikodu. Aby z niego skorzystać
wystarczy zakodować wszystkie pliki konfiguracyjne (łącznie z sygnaturką) w
UTF-8. 
</p>

<note>
Nadal może się zdarzyć, że w odebranej przez Mutta poczcie znajdzie się znak "?"
zamiast właściwego. Wynika to z tego, że niektórzy korzystają z klientów które
nie oznaczają wykorzystanego kodowania. Nie da się z tym wiele zrobić, poza
poproszeniem ich o prawidłową konfigurację klienta.
</note>

<p>
Dalsze informacje są dostępne na <uri
link="http://wiki.mutt.org/index.cgi?MuttFaq/Charset">Wiki Mutta</uri>.
</p>

</body>
</section>
<section>
<title>Less</title>
<body>

<p>
Programy <c>more</c> oraz <c>less</c> są dość często wykorzystywane, w
szczególności w połączeniu z <c>|</c> w celu dokładnego obejrzenia wyjścia
polecenia, na przykład <c>dmesg | less</c>. Podczas gdy <c>more</c> wymaga
jedynie, aby powłoka współpracowała z UTF-8, <c>less</c> wymaga ustawienia
zmiennej środowiskowej <c>LESSCHARSET</c> dla zapewnienia właściwego
wyświetlania znaków Unikodu. Może ona zostać ustawiona w
<path>/etc/profile</path> lub <path>~/.bash_profile</path>. Wykorzystując
ulubiony edytor należy dodać następujący wiersz do jednego z wymienionych
plików:
</p>

<pre caption="Konfiguracja zmiennej środowiskowej dla less">
LESSCHARSET=utf-8
</pre>

</body>
</section>
<section>
<title>Man</title>
<body>

<p>
Strony man są istotną częścią każdego komputera z Linuksem. Aby zapewnić
prawidłowe wyświetlanie znaków Unikodu należy zmodyfikować
<path>/etc/man.conf</path>:
</p>

<pre caption="Modyfikacja man.conf dla wsparcia Unikodu">
<comment>(To jest stary wiersz)</comment>
NROFF           /usr/bin/nroff -Tascii -c -mandoc
<comment>(Powyższe należy zastąpić poniższym)</comment>
NROFF           /usr/bin/nroff -mandoc -c
</pre>

</body>
</section>
<section>
<title>elinks oraz links</title>
<body>

<p>
Są to powszechnie wykorzystywane przeglądarki tekstowe i spróbujemy uruchomić w
nich wsparcie dla UTF-8. Dla <c>elinks</c> oraz <c>links</c> są na to dwa
sposoby, jeden z nich polega na wykorzystaniu opcji Setup z wewnątrz
przeglądarki, drugi zaś na edycji pliku konfiguracyjnego. Aby ustawić opcję z
wewnątrz przeglądarki należy uruchomić <c>elinks</c> lub <c>links</c> a
następnie wykorzystać <c>Alt+S</c>, aby wejść do menu Setup, następnie wybrać
pozycję Terminal options lub nacisnąć klawisz <c>T</c>. Teraz należy przewinąć w
dół i zaznaczyć ostatnią opcję: <c>UTF-8 I/O</c>. Następnie należy zapisać i
opuścić menu. Pod <c>links</c> może być potrzebne ponowne naciśnięcie
<c>Alt+S</c> oraz naciśnięcie <c>S</c> aby zapisać. Opcja w pliku
konfiguracyjnym pokazana jest poniżej.
</p>

<pre caption="Uruchamianie UTF-8 dla elinks/links">
<comment>(Dla elinksa należy wyedytować /etc/elinks/elinks.conf lub
~/.elinks/elinks.conf oraz dodać następujący wiersz)</comment>
set terminal.linux.utf_8_io = 1

<comment>(Dla linksa należy wyedytować ~/.links/links.cfg oraz dodać następujący wiersz)</comment>
terminal "xterm" 0 1 0 us-ascii utf-8
</pre>

</body>
</section>
<section>
<title>Testowanie całości</title>
<body>

<p>
Jest wiele stron poświęconych testowaniu UTF-8. <c>net-www/w3m</c>,
<c>net-www/links</c>, <c>net-www/elinks</c>, <c>net-www/lynx</c> oraz wszystkie
przeglądarki oparte na Mozilli (włącznie z Firefoksem) wspierają UTF-8.
Konqueror oraz Opera również mają pełne wsparcie UTF-8.
</p>

<p>
Korzystając z przeglądarek tekstowych należy upewnić się, że terminal obsługuje
Unikod.
</p>

<p>
Jeżeli zamiast niektórych znaków widoczne są kwadraty z literami oraz cyframi w
środku to oznacza to, że font nie zawiera danego znaku UTF-8. Zamiast tego
wyświetla pudełko z jego kodem szesnastkowym.
</p>

<ul>
  <li>
    <uri link="http://www.w3.org/2001/06/utf-8-test/UTF-8-demo.html">Strona
    testowa UTF-8 na W3C</uri>
  </li>
  <li>
    <uri link="http://titus.uni-frankfurt.de/indexe.htm?/unicode/unitest.htm">
    Strona testowa UTF-8 dostarczona przez Uniwersytet we Frankfurcie</uri>
  </li>
</ul>

</body>
</section>
<section>
<title>Metody wejściowe</title>
<body>

<p>
<e>Martwe klawisze</e> mogą być wykorzystane do wpisywania w X znaków, których
nie ma na klawiaturze. Działają one przez wciśnięcia prawego klawisza Alt (lub,
w niektórych krajach, AltGr) oraz opcjonalnie klawisza z niealfabetycznej części
klawiatury na lewo od klawisza return, puszczenia ich, a następnie naciśnięcia
znaku. Martwy klawisz powinien go zmodyfikować. Dalsze modyfikacje są możliwe
przez użycie klawisza Shift w tym samym czasie, co AltGr oraz modyfikatora.
</p>

<p>
Aby wykorzystać martwe klawisze w X potrzebny jest układ klawiatury, który to
wspiera. Większość układów europejskich zawiera martwe klawisze w domyślnym
wariancie. Niestety nie dotyczy to układów północnoamerykańskich. Pomimo pewnego
stopnia niekonsekwencji pomiędzy układami, najprostszym rozwiązaniem wydaje się
wykorzystania układu w postaci "pl_PL" zamiast "pl". Układ wybierany jest w
<path>/etc/X11/xorg.conf</path> w następujący sposób:
</p>

<pre caption="Fragment /etc/X11/xorg.conf">
Section "InputDevice"
    Identifier "Keyboard0"
    Driver     "kbd"
    Option     "XkbLayout" "pl_PL" <comment># Zamiast zwyczajnego "pl"</comment>
    <comment>(Tu inne opcje Xkb)</comment>
EndSection
</pre>

<note>
Ta zmiana potrzebna tylko jeśli używane są układy północnoamerykańskie lub inny
uład w którym nie działają martwe klawisze. Użytkownicy europejscy nie powinni
mieć problemu z martwymi klawiszami.
</note>

<p>
Ta zmiana zacznie działać dopiero po ponownym uruchomieniu serwera X. Aby
zastosować te zmiany od razu należy skorzystać z narzędzia <c>setxkbmap</c>, na
przykład <c>setxkbmap pl_PL</c>.
</p>

<p>
Najprościej jest opisać martwe klawisze za pomocą przykładów. Chociaż rezultaty
są zależne od lokalizacji idea pozostaje zawsze taka sama. Te przykłady
korzystają z UTF-8, więc aby z nich skorzystać należy albo skonfigurować
przeglądarkę do pokazywania strony jako UTF-8, albo wykorzystać lokalizację z
UTF-8.
</p>

<p>
Kiedy naciśnie się AltGr oraz [ jednocześnie, puści je, a następnie naciśnie a,
wyświetlone zostaje 'ä'. Kiedy naciśnie się AltGr oraz [, następnie e,
wyświetlone zostaje 'ë'. Kiedy naciśnie się AltGr oraz ;, wyświetlone zostaje
'á'. Kiedy naciśnie się AltGr oraz ; a następnie e wyświetlone zostanie 'é'.
</p>

<p>
Kiedy naciśnie się jednocześnie AltGr, Shift oraz [, puści się je, a następnie
naciśnie a, wyświetlone zostanie Skandynawskie 'å'. Podobnie, po naciśnięciu
altGr, Shift oraz [, puszczeniu <e>wyłącznie</e> [, następnie naciśnięciu go
ponownie, wyświetlone zostanie '°'.  Wprawdzie znak ten (U+02DA) wygląda
podobnie, ale nie jest on tym samym co symbol stopnia (U+00B0). Działa to
również dla innych akcentów produkowanych przez martwe klawisze - AltGr oraz [,
puszczenie tylko [ oraz naciśnięcie go ponownie da '¨'.
</p>

<p>
AltGr może też zostać użyty z samym klawiszem alfabetycznym. Na przykład, AltGr
i m dadzą w rezultacie małą literę mu: 'µ'. AltGr oraz s dadzą scharfes s: 'ß'.
Zgodnie z oczekiwaniami AltGr oraz 4 daje symbol Euro, '€'.
</p>

</body>
</section>
<section>
<title>Zasoby</title>
<body>

<ul>
  <li>
    <uri link="http://en.wikipedia.org/wiki/Unicode">Wpis Wikipedii o Unikodzie</uri>
  </li>
  <li>
    <uri link="http://en.wikipedia.org/wiki/UTF-8">Wpis Wikipedii o UTF-8</uri>
  </li>
  <li><uri link="http://www.unicode.org">Unicode.org</uri></li>
  <li><uri link="http://www.utf-8.com">UTF-8.com</uri></li>
  <li><uri link="http://www.ietf.org/rfc/rfc3629.txt">RFC 3629</uri></li>
  <li><uri link="http://www.ietf.org/rfc/rfc2277.txt">RFC 2277</uri></li>
  <li>
    <uri
    link="http://www.tbray.org/ongoing/When/200x/2003/04/26/UTF">Znaki vs. Bajty</uri>
  </li>
</ul>

</body>
</section>
</chapter>
</guide>
